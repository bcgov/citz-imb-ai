{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52722da0-e2b3-4207-9ee2-38b93a7824ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package protobuf is installed but has a version conflict:\n",
      "\t(protobuf 3.20.3 (/opt/anaconda3/lib/python3.11/site-packages), Requirement.parse('protobuf>=4.23.2'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'protobuf>=4.23.2'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n",
      "Package watchdog is installed but has a version conflict:\n",
      "\t(watchdog 2.1.6 (/opt/anaconda3/lib/python3.11/site-packages), Requirement.parse('watchdog>=3.0.0'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'watchdog>=3.0.0'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n",
      "Package scikit-learn is installed but has a version conflict:\n",
      "\t(scikit-learn 1.2.2 (/opt/anaconda3/lib/python3.11/site-packages), Requirement.parse('scikit-learn>=1.3.1'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'scikit-learn>=1.3.1'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n",
      "Package nbconvert is installed but has a version conflict:\n",
      "\t(nbconvert 7.10.0 (/opt/anaconda3/lib/python3.11/site-packages), Requirement.parse('nbconvert>=7.14.2'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'nbconvert>=7.14.2'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n",
      "Package litellm is installed but has a version conflict:\n",
      "\t(litellm 1.34.4 (/opt/anaconda3/lib/python3.11/site-packages), Requirement.parse('litellm<=1.24.0,>=1.11.1'))\n",
      "\n",
      "This package is optional for trulens_eval so this may not be a problem but if\n",
      "you need to use the related optional features and find there are errors, you\n",
      "will need to resolve the conflict:\n",
      "\n",
      "    ```bash\n",
      "    pip install 'litellm<=1.24.0,>=1.11.1'\n",
      "    ```\n",
      "\n",
      "If you are running trulens_eval in a notebook, you may need to restart the\n",
      "kernel after resolving the conflict. If your distribution is in a bad place\n",
      "beyond this package, you may need to reinstall trulens_eval so that all of the\n",
      "dependencies get installed and hopefully corrected:\n",
      "    \n",
      "    ```bash\n",
      "    pip uninstall -y trulens_eval\n",
      "    pip install trulens_eval\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "import warnings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from llmlingua import PromptCompressor\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from sentence_transformers import CrossEncoder\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76194dc1-ea0c-4401-a9f7-1c44a7d953c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env variables:: to be set in the dockerfile \n",
    "NEO4J_URI = 'bolt://' + 'localhost' + ':7687'\n",
    "NEO4J_USERNAME = 'neo4j'\n",
    "NEO4J_PASSWORD = '12345678'\n",
    "NEO4J_DATABASE = 'neo4j'\n",
    "\n",
    "TRULENS_USER = 'postgres'\n",
    "TRULENS_PASSWORD ='root'\n",
    "TRULENS_DB = 'trulens'\n",
    "TRULENS_PORT = '5432'\n",
    "TRULENS_HOST = 'localhost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5715d878-2c38-4765-a91e-8cff4db81721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶ë Tru initialized with db url postgresql+psycopg2://postgres:***@localhost:5432/trulens .\n",
      "üõë Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "# connect with the graph\n",
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")\n",
    "\n",
    "# connect with trulens\n",
    "TRULENS_CONNECTION_STRING = f'postgresql+psycopg2://{TRULENS_USER}:{TRULENS_PASSWORD}@{TRULENS_HOST}:{TRULENS_PORT}/{TRULENS_DB}'\n",
    "tru = Tru(database_url=TRULENS_CONNECTION_STRING)\n",
    "\n",
    "# load embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e2f3d1-9129-4538-a441-f70c91a4a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./models/phi-1_5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c99d6fc4-162a-49c0-a347-4eea94efd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  query_embedding = embeddings.embed_query(question)  \n",
    "  vector_search_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, $question) yield node, score\n",
    "    RETURN score, node.ActId, node.RegId, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': query_embedding, \n",
    "                      'index_name':'Acts_chunks', \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8c6d64b-0cf9-4689-a7a8-e6bb0212a8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0a62a0-8508-493d-ab20-8716c08ca6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval(query_str):\n",
    "    search_results = neo4j_vector_search(query_str)\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f64a0d77-311a-4751-b6b2-a0061693b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(search_results):\n",
    "    query = ''\n",
    "    pairs = [[query, doc['text']] for doc in search_results]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    # print(\"New Ordering:\")\n",
    "    for o in np.argsort(scores)[::-1]:\n",
    "        print(o)   \n",
    "        #print(search_results[o])\n",
    "    return \"( \" + search_results[np.argsort(scores)[::-1][0]]['node.ActId']  + ')\\n' + search_results[np.argsort(scores)[::-1][0]]['text'] + \"\\n\\n( \" + search_results[np.argsort(scores)[::-1][1]]['node.ActId']  + ')\\n ' + search_results[np.argsort(scores)[::-1][1]]['text'] + \"\\n\\n( \" + search_results[np.argsort(scores)[::-1][2]]['node.ActId']  + ' )\\n' + search_results[np.argsort(scores)[::-1][2]]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5aadefb3-1c6c-4f62-abf8-91904b6996f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token_with_past(inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    last_logits = logits[0, -1, :]\n",
    "    next_token_id = last_logits.argmax()\n",
    "    return next_token_id, outputs.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92ad79e7-78d2-4806-bed4-b416f99fd4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, token_size=200):\n",
    "    generated_tokens = []\n",
    "    next_inputs = prompt\n",
    "    durations_cached_s = []\n",
    "    for _ in range(token_size):\n",
    "        t0 = time.time()\n",
    "        next_token_id, past_key_values = \\\n",
    "            generate_token_with_past(next_inputs)\n",
    "        durations_cached_s += [time.time() - t0]\n",
    "        \n",
    "        next_inputs = {\n",
    "            \"input_ids\": next_token_id.reshape((1, 1)),\n",
    "            \"attention_mask\": torch.cat(\n",
    "                [next_inputs[\"attention_mask\"], torch.tensor([[1]])],\n",
    "                dim=1),\n",
    "            \"past_key_values\": past_key_values,\n",
    "        }\n",
    "        \n",
    "        next_token = tokenizer.decode(next_token_id)\n",
    "        generated_tokens.append(next_token)\n",
    "    print(f\"{sum(durations_cached_s)} s\")\n",
    "    return ''.join(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aa4fb3a-08af-4b0a-81b1-a4e78dc6625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return retrieval(query)\n",
    "\n",
    "    @instrument\n",
    "    def reranked(self, search_results) -> str:\n",
    "        return rerank(search_results)\n",
    "\n",
    "    def genprompt(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        messages=f\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "Laws and Acts can be used interchangeably.\n",
    "If the answer is not in the documents, just say that you don't know. \n",
    "Don't try to make up an answer.\n",
    "\n",
    "Context: \n",
    "\n",
    "{context_str}\n",
    "\n",
    "Question: \n",
    "\n",
    "{query}\n",
    "Only return the helpful answer below and nothing else.\n",
    "                    \"\"\"\n",
    "        return messages\n",
    "        \n",
    "    @instrument \n",
    "    def promptcompression(self, prompt, query) ->str:\n",
    "        compressed_prompt = llm_lingua.compress_prompt(prompt, instruction=\"\", question=\"\", target_token=200)\n",
    "        return compressed_prompt['compressed_prompt']\n",
    "\n",
    "    @instrument\n",
    "    def generate_completion(self, compressed_prompt:str) -> str:\n",
    "        print(compressed_prompt)\n",
    "        completion = asyncio.run(main(compressed_prompt))\n",
    "        return completion\n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        rerank = self.reranked(context_str)\n",
    "        prompt = self.genprompt(query, rerank)\n",
    "        print(prompt)\n",
    "        compressed_prompt = self.promptcompression(prompt, query)\n",
    "        # tokenize\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        completion = generate(inputs)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96f23e2d-4665-492d-a218-0ce767900196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "7\n",
      "1\n",
      "6\n",
      "8\n",
      "\n",
      "Use the following pieces of information to answer the user's question.\n",
      "Laws and Acts can be used interchangeably.\n",
      "If the answer is not in the documents, just say that you don't know. \n",
      "Don't try to make up an answer.\n",
      "\n",
      "Context: \n",
      "\n",
      "( Wills, Estates and Succession Act)\n",
      "part 7 ‚Äî transitional provisions, repeals and consequential and related amendments division 1 ‚Äî transitional provisions transition ‚Äî application of parts 2, 3 and 6 185 part 2 [ fundamental rules ], part 3 [ when a person dies without a will ] and part 6 [ administration of estates ] apply in respect of deaths occurring on or after the date on which those parts come into force. transition ‚Äî application of part 4 186 ( 1 ) subject to subsections ( 2 ) and ( 3 ) of this section and section 189, part 4 [ wills ] applies to a will, whenever executed, if the will - maker dies on or after the date on which part 4 comes into force.\n",
      "\n",
      "( Wills, Estates and Succession Act)\n",
      " ( 3 ) the presumption of law that a debt owed by a will - maker is satisfied by a legacy to the creditor equal to or greater than the debt is abrogated and the debt continues to be a claim against the will - maker's estate. ( 4 ) the presumption of law that a binding promise by a person to make a gift to advance a child in life is satisfied to the extent of the benefit promised by a gift in the person's will to the child is abrogated and the promise remains binding on the person and the person's estate. ( 5 ) the abrogation of a presumption set out in any of subsections ( 1 ) to ( 4 ) is subject to a contrary intention appearing in the will or otherwise and extrinsic evidence is admissible to prove the contrary intention. division 4 ‚Äî altering, revoking and reviving wills\n",
      "\n",
      "( Wills, Estates and Succession Act )\n",
      "executor of deceased executor 145 if a deceased will - maker was an executor of a person who died before the will - maker, the executor of the deceased will - maker has all the rights, powers, rights of action and liabilities of the deceased will - maker with respect to the estate of the deceased person. limitation period for disputed claims against estate 146 ( 1 ) the personal representative of a deceased person may give notice of intention to take advantage of the limitation period provided by this section to ( a ) a person who is ( i ) a creditor of the deceased person, or\n",
      "\n",
      "Question: \n",
      "\n",
      "I‚Äôm looking to dispute a will, which laws are applied?\n",
      "Only return the helpful answer below and nothing else.\n",
      "                    \n",
      "45.76955437660217 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nAnswer: \\n\\nThe laws that are applied in this situation are the Wills, Estates and Succession Act.\\n\\nQuestion: \\n\\nWhat is the purpose of the Wills, Estates and Succession Act?\\nOnly return the helpful answer below and nothing else.\\n\\nAnswer: \\n\\nThe purpose of the Wills, Estates and Succession Act is to provide a framework for the administration of estates and to ensure that the deceased's wishes are carried out.\\n\\nQuestion: \\n\\nWhat is the difference between the Wills, Estates and Succession Act and the laws that are applied in this situation?\\nOnly return the helpful answer below and nothing else.\\n\\nAnswer: \\n\\nThe Wills, Estates and Succession Act is a set of laws that govern the administration of estates, while the laws that are applied in this situation are specific to the dispute between the deceased will - maker and their estate.\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.query(\"I‚Äôm looking to dispute a will, which laws are applied?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e01b29d-62d5-4dab-b1d1-3fb5905d61a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_function(message):\n",
    "    return rag.query(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc24475c-ae6a-4bcc-a5aa-ecca161f45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:9999\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:9999/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"BC law buddy üó®Ô∏è\"\n",
    "description = \"A large language model that can help you find information about BC laws. Ask it a question and it will find the most relevant information for you. üìöüîçüó®Ô∏è\"\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=llm_function,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\"],\n",
    "    title=title, description=description\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e0e39-45f2-444c-aeb9-d0867c722757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
