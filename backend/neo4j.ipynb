{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aae9303-ba38-4a93-bb77-26ec21d832b1",
   "metadata": {},
   "source": [
    "# This notebook uses the NEO4J graph database to associate acts and regulations \n",
    "### The purpose of using a graph database is to understand how graphs can be connected for better retrieval. \n",
    "#### There are a few advantages of using a graph database over traditional databasese and this notebook tries to explore more advantages\n",
    "- It is easier to grow the data in this database without any complex migration scripts or ORM\n",
    "- Much easier to link different data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61af095",
   "metadata": {},
   "source": [
    "## Please run s3_v2.py before running this notebook,. This file will download all the regulation and Acts in html format and store it in the appropriate directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4391ee9-c27f-496b-bcc9-ef0ed903a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install neo4j\n",
    "!pip install bs4\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54be3d-7670-463f-a13d-9482d394af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "import warnings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911112d4-41bc-452f-91b6-942b37b8e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0131a-4016-4724-b184-35b024773b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = 'bolt://' + os.getenv('NEO4J_HOST') + ':7687'\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USER')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = 'neo4j' #os.getenv('NEO4J_DB')\n",
    "print(NEO4J_URI)\n",
    "print(NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2ed57-cd25-441b-b193-43e9f2118a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b6ccc6-c16d-440d-a439-42cdd2a60184",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (n) \n",
    "  RETURN count(n)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1410c8-7469-4620-aa96-6e0e7ecf4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(cypher)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c1947-5700-4610-bae2-ccf46861e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all HTML\n",
    "Acts_documents = SimpleDirectoryReader(\"./HTML_Acts\").load_data()\n",
    "Regulations_documents = SimpleDirectoryReader(\"./HTML_Regulations\").load_data()\n",
    "print((len(Acts_documents)))\n",
    "print((len(Regulations_documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0dd2c-7a7c-4912-ae94-54d9998b0656",
   "metadata": {},
   "source": [
    "In the next section we try to loop through all the Acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81b357-f9ea-4f73-b5b4-ad32049dc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Regulations_documents[1].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c8431-42d0-452f-a46a-3ee7ac79a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    title = soup.find_all(\"h2\")\n",
    "    title = title[0].get_text()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f8a21-2e21-4f3e-9534-023cf9edbae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions(sections):\n",
    "    for index, section in enumerate(sections):\n",
    "        heading = section.find(\"h4\")\n",
    "        print(heading.get_text())\n",
    "        if 'Definition' in heading.get_text():\n",
    "            definition = section\n",
    "            return definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb1bf8-f928-45ba-bf74-e8903da84cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preamble(soup):\n",
    "    preamble = soup.find_all(\"div\", class_='preamble')\n",
    "    if preamble:\n",
    "        print(preamble[0].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c555f-021a-4240-819c-1c5bcaf2980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_from_file(file, soup):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    #print(f'Processing {file}') \n",
    "    item_text = file #file_as_object[item] # grab the text of the item\n",
    "    item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "    title  = get_title(soup)\n",
    "    #print(title)\n",
    "    chunk_seq_id = 0\n",
    "    for chunk in item_text_chunks: # only take the first 20 chunks\n",
    "        #form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "        # finally, construct a record with metadata and the chunk text\n",
    "        chunks_with_metadata.append({\n",
    "            'text': chunk, \n",
    "            # metadata from looping...\n",
    "            'chunkSeqId': chunk_seq_id,\n",
    "            'chunkId': f'{title}-chunk{chunk_seq_id:04d}',\n",
    "            'ActId': f'{title}',\n",
    "            # constructed metadata...\n",
    "            # metadata from file...\n",
    "        })\n",
    "        chunk_seq_id += 1\n",
    "        #print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016671b9-a4a5-4f33-95c7-3a4cc4dca522",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text,\n",
    "        mergedChunk.ActId = $chunkParam.ActId\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481dafaa-e733-48d1-9833-31bc6766e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bde9de-39d1-4502-b13c-4cae59f5febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, Acts in enumerate(Acts_documents):\n",
    "    soup = BeautifulSoup(Acts.get_text(), 'html.parser')\n",
    "    #sections = soup.find_all(\"div\", class_='section')\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 2000,\n",
    "        chunk_overlap  = 200,\n",
    "        length_function = len,\n",
    "        is_separator_regex = False,\n",
    "    )\n",
    "    item1_text = soup.get_text()\n",
    "   # item1_text_chunks = text_splitter.split_text(item1_text)\n",
    "    first_file_chunks = split_data_from_file(item1_text, soup)\n",
    "    #print(first_file_chunks[0])\n",
    "    kg.query(merge_chunk_node_query, \n",
    "         params={'chunkParam':first_file_chunks[0]})\n",
    "    kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "\"\"\")\n",
    "    node_count = 0\n",
    "    for chunk in first_file_chunks:\n",
    "        print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkSeqId']}\")\n",
    "        kg.query(merge_chunk_node_query, \n",
    "                params={\n",
    "                    'chunkParam': chunk\n",
    "                })\n",
    "        node_count += 1\n",
    "    #print(f\"Created {node_count} nodes\")\n",
    "    kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")\n",
    "    kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `Acts_chunks` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 384,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")\n",
    "    # Create the embeddings\n",
    "    for chunk in first_file_chunks:\n",
    "        query_result = embeddings.embed_query(chunk['text'])\n",
    "        #print(chunk['chunkId'])\n",
    "        match =        kg.query(\"\"\"\n",
    "        MATCH (chunk:Chunk) WHERE\n",
    "        chunk.textEmbedding IS NULL\n",
    "        AND chunk.chunkId = $chunkId\n",
    "        AND chunk.chunkSeqId = $chunkSeqId\n",
    "        RETURN chunk\n",
    "        \"\"\",\n",
    "        params={\"chunkSeqId\": chunk['chunkSeqId'], \"chunkId\": chunk['chunkId'], \"ActId\":chunk['ActId'] })\n",
    "        #print(match)\n",
    "        kg.query(\"\"\"\n",
    "        MATCH (chunk:Chunk) WHERE\n",
    "        chunk.textEmbedding IS NULL\n",
    "        AND chunk.chunkSeqId = $chunkSeqId\n",
    "        AND chunk.chunkId = $chunkId\n",
    "        CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", $vector)\n",
    "    \"\"\", \n",
    "    params={\"chunkSeqId\": chunk['chunkSeqId'], \"chunkId\": chunk['chunkId'], \"ActId\":chunk['ActId'], \"vector\": query_result} )\n",
    "    kg.query(\"SHOW INDEXES\")\n",
    "    #break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c57db3-2d14-4c1b-8871-b3023d9da4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3a360-d571-4d92-8082-89b704a70cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  query_embedding = embeddings.embed_query(question)  \n",
    "  vector_search_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, $question) yield node, score\n",
    "    RETURN score, node.ActId, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = kg.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': query_embedding, \n",
    "                      'index_name':'Acts_chunks', \n",
    "                      'top_k': 10})\n",
    "  return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9ee9c-4514-4b97-8336-c09d832d1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = neo4j_vector_search(\n",
    "    'When an employee is fired what needs to be done next?'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c5ee1-6382-4aa2-8ea4-b8a685368001",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b679666e-edb4-48b8-97a5-40870c26c3ae",
   "metadata": {},
   "source": [
    "### Loop through all laws, associate all the chunks, make a parent ACT node and atacching the children chunks to the corresponding parent chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b050381-7459-46ff-8d45-207a793ef5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_info_list_fn(actId):\n",
    "    cypher = \"\"\"\n",
    "      MATCH (anyChunk:Chunk) \n",
    "      WHERE anyChunk.ActId = $ActId\n",
    "      WITH anyChunk LIMIT 1\n",
    "      RETURN anyChunk { .ActId } as ActInfo\n",
    "    \"\"\"\n",
    "    act_info_list = kg.query(cypher, params={'ActId': actId})\n",
    "    return act_info_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22278a7f-3794-40b4-a4e8-2d6108e21401",
   "metadata": {},
   "source": [
    "### Connect chunks to their parent form with a PART_OF relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abe4c1-b35b-4a74-851a-d1cf56329df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_act_node(act_info):\n",
    "    cypher = \"\"\"\n",
    "        MERGE (f:Act {ActId: $formInfoParam.ActId })\n",
    "          ON CREATE \n",
    "            SET f.ActId = $formInfoParam.ActId\n",
    "            \"\"\"\n",
    "    kg.query(cypher, params={'formInfoParam': act_info})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffddc2-8431-4f4a-a01c-4a33b40755c7",
   "metadata": {},
   "source": [
    "### Add a NEXT relationship between subsequent chunks\n",
    "- Use the `apoc.nodes.link` function from Neo4j to link ordered list of `Chunk` nodes with a `NEXT` relationship\n",
    "- Do this for just the \"Item 1\" section to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b37d9-1d0f-4a17-b6f8-e265174896eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunk_relationship(act_info):\n",
    "    cypher = \"\"\"\n",
    "  MATCH (from_same_section:Chunk)\n",
    "  WHERE from_same_section.ActId = $ActParam\n",
    "  WITH from_same_section\n",
    "    ORDER BY from_same_section.chunkSeqId ASC\n",
    "  WITH collect(from_same_section) as section_chunk_list\n",
    "    CALL apoc.nodes.link(\n",
    "        section_chunk_list, \n",
    "        \"NEXT\", \n",
    "        {avoidDuplicates: true}\n",
    "    )  // NEW!!!\n",
    "  RETURN size(section_chunk_list)\n",
    "\"\"\"\n",
    "    kg.query(cypher, params={'ActParam': act_info['ActId']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeb61da-c389-4869-b48f-e509cf4206a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_chunk_to_parent():\n",
    "    cypher = \"\"\"\n",
    "      MATCH (c:Chunk), (f:Act)\n",
    "        WHERE c.ActId = f.ActId\n",
    "      MERGE (c)-[newRelationship:PART_OF]->(f)\n",
    "      RETURN count(newRelationship)\n",
    "    \"\"\"\n",
    "    kg.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d236fb-232c-427a-aab3-464ae5bfbc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, Acts in enumerate(Acts_documents):\n",
    "    soup = BeautifulSoup(Acts.get_text(), 'html.parser')\n",
    "    title  = get_title(soup)\n",
    "    act_info_lists = act_info_list_fn(title)\n",
    "    for act_info_list in act_info_lists:\n",
    "        act_info = act_info_list['ActInfo']        \n",
    "        create_parent_act_node(act_info)\n",
    "        create_chunk_relationship(act_info)\n",
    "        connect_chunk_to_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574716d-67df-4d67-92f6-6122f8971ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5175101-e17b-4ac0-9710-f5767f2fe7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
