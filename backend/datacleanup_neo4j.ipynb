{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55cb036-12e8-4542-b540-1851bc21bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install neo4j\n",
    "!pip install bs4\n",
    "!pip install llama-index\n",
    "!pip uninstall -y trulens_eval\n",
    "!pip install trulens-eval==0.25.1\n",
    "!pip install llmlingua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800097d-8bcd-44ef-b328-d2f936f5cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y trulens_eval\n",
    "!pip install trulens-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb69924-b754-4082-97ad-c640b32b2312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df74b51-25ab-4acb-b9e1-022f8fb7872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "import warnings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from llmlingua import PromptCompressor\n",
    "import re\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84993598-ecc2-4eeb-a1ad-d1ee9813f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_wrap(string, n_chars=72):\n",
    "    # Wrap a string at the next space after n_chars\n",
    "    if len(string) < n_chars:\n",
    "        return string\n",
    "    else:\n",
    "        return string[:n_chars].rsplit(' ', 1)[0] + '\\n' + word_wrap(string[len(string[:n_chars].rsplit(' ', 1)[0])+1:], n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b8599-83bd-4b87-90aa-8aee7751e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = 'bolt://' + os.getenv('NEO4J_HOST') + ':7687'\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USER')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = 'neo4j' #os.getenv('NEO4J_DB')\n",
    "print(NEO4J_URI)\n",
    "print(NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18877c47-5303-45d6-992b-d6760dde8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cd2f1-2d4d-4c7d-80d2-667352cb686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (n) \n",
    "  RETURN count(n)\n",
    "  \"\"\"\n",
    "result = kg.query(cypher)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc37b8-ba42-408c-b504-ad047bbdfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795d6f2-bb1c-40bd-ab99-00436cbf9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = lambda x: {\"filename\": x}\n",
    "Acts_documents = SimpleDirectoryReader(\"./XML\",file_metadata=file_metadata).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dede1b-b087-4711-b6d9-e7b759e9522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_data = Acts_documents[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ac9f32-657c-4975-9bc9-a0f3c59d7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    title = soup.find_all(\"h2\")\n",
    "    title = title[0].get_text().strip()\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff7848-7c8d-4c69-bc30-0fdd0ec6987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_definitions(sections):\n",
    "    for index, section in enumerate(sections):\n",
    "        heading = section.find(\"h4\")\n",
    "        print(heading.get_text())\n",
    "        if 'Definition' in heading.get_text():\n",
    "            definition = section\n",
    "            return definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fa7f4-1bf7-4285-92d8-65322cd8e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preamble(soup):\n",
    "    preamble = soup.find_all(\"div\", class_='preamble')\n",
    "    if preamble:\n",
    "        print(preamble[0].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ba789-45b9-4070-84d8-6605d63af452",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = BeautifulSoup(act_data, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836151a3-89dc-49a8-9354-4d8a802af0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65048244-3424-4fe8-b43a-5691958fea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = file.find_all('act:title')\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c460ee6-001f-4f40-904c-48736b9bf915",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = file.find_all('bcl:definition')\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f639da-84a8-4820-ad3e-02e6194bab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sections = file.find_all('bcl:section')\n",
    "print(num_sections)\n",
    "print(len(num_sections)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849dc678-c299-416e-be23-9c642c982354",
   "metadata": {},
   "source": [
    "## Working with the 1st section\n",
    "\n",
    "#### bcl - B.C Laws #####\n",
    "bcl:num gives the number of sections, subsections and something more\n",
    "\n",
    "bcl:section gives all the sections and subsections\n",
    "\n",
    "bcl:marginalnote gices the section heading\n",
    "\n",
    "if the section is a definition then each definition has a definition tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5b91b-3302-40a0-bb6b-c940582cbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_1 = num_sections[2]\n",
    "section_heading = section_1.find_all('bcl:marginalnote')\n",
    "section_definitions = section_1.find_all('bcl:definition')\n",
    "section_subsection = section_1.find_all('bcl:subsection')\n",
    "print(section_1)\n",
    "print(len(section_subsection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46c7fa-7cd7-4d31-8053-0f3abce8b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9da5c9-de00-4dfe-bae5-96bc3261902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def link_references(str, index):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebf4b2-eb39-4cc7-9aac-8d58313105a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:UpdatedChunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text,\n",
    "        mergedChunk.ActId = $chunkParam.ActId,\n",
    "        mergedChunk.sectionId = $chunkParam.sectionId,\n",
    "        mergedChunk.sectionName = $chunkParam.sectionName\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0ffcb-ac6b-412a-9825-b62b74f5abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_chunk_node_query =  \"\"\"\n",
    "        MATCH (chunk:UpdatedChunk) WHERE\n",
    "        chunk.chunkId = $chunkParam.chunkId\n",
    "        AND chunk.chunkSeqId = $chunkParam.chunkSeqId\n",
    "        AND chunk.ActId = $chunkParam.ActId\n",
    "        AND chunk.sectionId = $chunkParam.sectionId\n",
    "        AND chunk.sectionName = $chunkParam.sectionName\n",
    "        RETURN chunk\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73b3c22-9afb-460a-a511-0167d590df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will search for any reference that has the word section or subsection followed by a number\n",
    "def extract_references(str, index):\n",
    "    references = re.findall(r\"section (\\d+)\", str)\n",
    "    #print(references)\n",
    "    #if (len(references)):\n",
    "        #link_references(str, index)\n",
    "        #print(index)\n",
    "        #cache[index].append(references)\n",
    "print(cache)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161709f-5d67-4fd7-8b1a-2c5d2fe21edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_links(subsection):\n",
    "    if not subsection:\n",
    "        return\n",
    "    if (subsection.find_all(\"bcl:link\")):\n",
    "        xml_link = subsection.find_all(\"bcl:link\")[0]['xlink:href']\n",
    "        display(HTML(f'<a href=\"{xml_link}\">{subsection.find_all(\"bcl:link\")[0].get_text()}</a>'))\n",
    "    extract_references(subsection.get_text().replace(\"\\n\\n\", \"\").replace(\"\\r\", \"\"), index)\n",
    "    #print(subsection)\n",
    "    #print(subsection.get_text().replace(\"\\n\", \" \").replace(\"\\r\", \" \"))\n",
    "    return subsection.get_text().replace(\"\\n\", \" \").replace(\"\\r\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30df312-23ba-4976-b25b-cb118fe3b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get subsection\n",
    "def subsection(section_definitions, index):\n",
    "    string = \"\"\n",
    "    for subsection_index, subsection in enumerate(section_definitions):\n",
    "        nested_section = subsection.find_all('bcl:num')\n",
    "        string += \"\\n\" + find_links(subsection)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23416766-7217-4a2b-9ca0-d8c16b082521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(token_split_texts,title, section_heading, section_id):\n",
    "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
    "    chunk_seq_id = 0\n",
    "    for chunk in token_split_texts: # only take the first 20 chunks\n",
    "        #form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
    "        # finally, construct a record with metadata and the chunk text\n",
    "        chunks_with_metadata.append({\n",
    "            'text': chunk, \n",
    "            # metadata from looping...\n",
    "            'chunkSeqId': chunk_seq_id,\n",
    "            'chunkId': f'{title}-chunk-{section_heading}-{chunk_seq_id:04d}',\n",
    "            'ActId': f'{title}',\n",
    "            'sectionId': f'{section_id}',\n",
    "            'sectionName':f'{section_heading}',\n",
    "            # constructed metadata...\n",
    "            # metadata from file...\n",
    "        })\n",
    "        chunk_seq_id += 1\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa4c984-ca82-4a28-b699-04c1bb96013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(item_text, title, section_heading, section_id):\n",
    "    item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=20, tokens_per_chunk=256)\n",
    "    token_split_texts = []\n",
    "    for text in item_text_chunks:\n",
    "        token_split_texts += token_splitter.split_text(text)\n",
    "    meta_data = create_metadata(token_split_texts,title, section_heading, section_id)    \n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715225f5-d64b-45c4-9c63-d2c784a559a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_chunks = \"\"\"\n",
    "      MATCH (chunk:UpdatedChunk), (f:UpdatedChunk)\n",
    "      WHERE\n",
    "        chunk.chunkId = $chunkParam.chunkId\n",
    "        AND chunk.chunkSeqId = $chunkParam.chunkSeqId\n",
    "        AND chunk.ActId = $chunkParam.ActId\n",
    "        AND chunk.sectionId = $chunkParam.sectionId\n",
    "        AND chunk.sectionName = $chunkParam.sectionName\n",
    "        AND f.ActId = $chunkParam.ActId\n",
    "        AND f.sectionId = $chunkParam.connectnedsectionId\n",
    "        AND f.chunkSeqId = 1\n",
    "      MERGE (chunk)-[newRelationship:REFERENCE]->(f)\n",
    "      RETURN count(newRelationship)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d3e50-fd5c-48d9-9eb3-ee8ab6adeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_create_reference(match):\n",
    "    #print(match[0]['chunk'])\n",
    "    text = match[0]['chunk']['text']\n",
    "    references = re.findall(r\"(?i)(?:section)\\s+(\\d+|\\(\\d+\\))(?:\\s*\\([a-z]\\))?\", text)\n",
    "    if (references):\n",
    "        print(match[0]['chunk'])\n",
    "        print(references)\n",
    "        # create the edges\n",
    "        print(\"Match found - creating references\")\n",
    "        chunk_seq_id = match[0]['chunk']['chunkSeqId']\n",
    "        section_heading = match[0]['chunk']['sectionName']\n",
    "        section_id = match[0]['chunk']['sectionId']\n",
    "        chunk = {\n",
    "            'text': text, \n",
    "            # metadata from looping...\n",
    "            'chunkSeqId': match[0]['chunk']['chunkSeqId'],\n",
    "            'chunkId': match[0]['chunk']['chunkId'],\n",
    "            'ActId': match[0]['chunk']['ActId'],\n",
    "            'sectionId': match[0]['chunk']['sectionId'],\n",
    "            'sectionName': match[0]['chunk']['sectionName'],\n",
    "            'connectnedsectionId': references[0]\n",
    "        }\n",
    "        result = kg.query(connect_chunks,\n",
    "                params={\n",
    "                    'chunkParam':chunk\n",
    "                }\n",
    "                )\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb3e87-7986-4efc-99ed-622680aa82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunk_neo4j(tokens, search=False):\n",
    "    match_found = []\n",
    "    for chunk in tokens:\n",
    "        if search:\n",
    "            print('search')\n",
    "            match = kg.query(match_chunk_node_query, \n",
    "                    params={\n",
    "                        'chunkParam': chunk\n",
    "                    })\n",
    "            if (match):\n",
    "                search_create_reference(match)\n",
    "            match_found.append(match)\n",
    "        else:\n",
    "            print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkSeqId']}\")\n",
    "            kg.query(merge_chunk_node_query, \n",
    "                    params={\n",
    "                        'chunkParam': chunk\n",
    "                    })\n",
    "    return match_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd475e-989e-49a6-9944-4b70a3c7d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file, search=False):\n",
    "    #get the ACT's title\n",
    "    title = file.find_all('act:title')[0].get_text()\n",
    "    print(title)\n",
    "    #get all the sections\n",
    "    preamble = file.find_all('bcl:preamble')\n",
    "    if (preamble):\n",
    "        item_text = subsection(preamble, 0)\n",
    "        token = create_chunks(item_text, title, 'preamble', 0)\n",
    "    sections = file.find_all('bcl:section')\n",
    "    #find the definition subsection\n",
    "    for index, section in enumerate(sections):\n",
    "        section_heading = section.find_all('bcl:marginalnote')[0].get_text()\n",
    "        #if (section_heading):\n",
    "        #    section_heading = section_heading[0].get_text()\n",
    "        #print(index)\n",
    "        #print(\"-----\" + section_heading + \"------\\n\")\n",
    "        section_definitions = section.find_all('bcl:definition')\n",
    "        if (len(section_definitions) < 1):\n",
    "            #find the remaining subsection\n",
    "            section_subsection = section.find_all('bcl:subsection')\n",
    "            if len(section_subsection):\n",
    "                item_text = subsection(section_subsection, index+1)\n",
    "                #print(item_text)\n",
    "                token = create_chunks(item_text, title, section_heading, index+1)\n",
    "            else:\n",
    "                item_text = find_links(section)\n",
    "                token = create_chunks(item_text, title, section_heading, index+1)\n",
    "        else:\n",
    "            item_text = subsection(section_definitions, index+1)\n",
    "            #print(item_text)\n",
    "            token = create_chunks(item_text, title, section_heading, index+1)\n",
    "        #print(token)\n",
    "        #print(len(token))\n",
    "        #print(\"\\n\\n\")\n",
    "        #if (index > 1):    \n",
    "            #break\n",
    "        found = create_chunk_neo4j(token, search)\n",
    "        if (search):\n",
    "            return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde21a12-dbcf-40da-9aba-01ed87761358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, Acts in enumerate(Acts_documents):\n",
    "    soup = BeautifulSoup(Acts.get_text(), 'xml')\n",
    "    extract_data(soup)\n",
    "    #sections = soup.find_all(\"div\", class_='section')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738cb61-98fa-4922-92a9-242aed32592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets match the chunks and create the links withing the document\n",
    "search_found = []\n",
    "for index, Acts in enumerate(Acts_documents):\n",
    "    soup = BeautifulSoup(Acts.get_text(), 'xml')\n",
    "    search_found.append(extract_data(soup, True))\n",
    "    #sections = soup.find_all(\"div\", class_='section')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41352fbd-687e-436a-a49a-1b336985053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da094ef3-bdb4-4207-8b7e-627d5873ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= search_found[0][0][0]['chunk']['text']\n",
    "print(text)\n",
    "references = re.findall(r\"(?i)(?:section)\\s+(\\d+|\\(\\d+\\))(?:\\s*\\([a-z]\\))?\", text)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f233eb3-3f87-4618-8a51-6510d3ca7552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
