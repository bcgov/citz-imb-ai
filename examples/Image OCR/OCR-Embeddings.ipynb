{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Image Processing and Vector Search\n",
    "\n",
    "## Overview\n",
    "This notebook processes OCR (Optical Character Recognition) data extracted from images and indexes them in Neo4j for semantic search. The OCR text comes from a structured JSON file containing descriptions of various images from legal documents. The implementation uses sequential chunking with NEXT relationships to maintain context between chunks.\n",
    "\n",
    "## Workflow\n",
    "1. **Data Loading**: Loads OCR text data from a nested JSON structure\n",
    "2. **Text Preprocessing**: Replaces line breaks with spaces for better readability\n",
    "3. **Token-Based Chunking**: Splits full text into manageable chunks (256 tokens with 20 token overlap)\n",
    "4. **Metadata Creation**: Adds structured metadata including ImageUrl and document references\n",
    "5. **Embedding Generation**: Creates vector embeddings using all-MiniLM-L6-v2\n",
    "6. **Sequential Storage**: Stores chunks as ImageChunk nodes with NEXT relationships between them\n",
    "7. **Document Relationships**: Establishes PART_OF relationships between chunks and document types\n",
    "8. **Vector Search**: Enables semantic search across all image descriptions\n",
    "9. **Context Retrieval**: Returns neighboring chunks for better context awareness\n",
    "10. **Reranking**: Improves search relevance using a cross-encoder reranking model\n",
    "\n",
    "## Data Structure\n",
    "The OCR data follows a hierarchical structure:\n",
    "- Folder (e.g., Acts, Regulations)\n",
    "  - Subfolder (e.g., Election Act) - stored with spaces instead of underscores\n",
    "    - File (e.g., 96106_greatseal.gif)\n",
    "      - OCR Text (processed as a single continuous text)\n",
    "\n",
    "## Neo4j Schema\n",
    "- **Node Labels**: \n",
    "  - `ImageChunk`: Contains text chunks from OCR data\n",
    "  - `UpdatedChunksAndImagesv4`: Combined label for unified vector search\n",
    "  - Document types: `Act`, `Regulation`, etc.\n",
    "- **Node Properties**:\n",
    "  - `text`: The chunk text content\n",
    "  - `textEmbedding`: Vector representation of the text\n",
    "  - `ImageUrl`: URL to the source image\n",
    "  - `chunkSeqId`: Sequential ID to maintain chunk order\n",
    "  - `folder`, `subfolder`, `file_name`: Source location metadata\n",
    "  - `ActId`/`RegId`: Document identifiers with spaces (not underscores)\n",
    "- **Relationships**: \n",
    "  - `(ImageChunk)-[:PART_OF]->(DocumentType)`: Links chunks to their document\n",
    "  - `(ImageChunk)-[:NEXT]->(ImageChunk)`: Sequential link between adjacent chunks\n",
    "- **Vector Index**: Applied on the `textEmbedding` property\n",
    "\n",
    "## Key Features\n",
    "- **Continuous Text Processing**: Processes OCR text as a whole without section splitting\n",
    "- **Sequential Chunking**: Maintains relationships between adjacent chunks\n",
    "- **Context-Aware Search**: Retrieves neighboring chunks for better context understanding\n",
    "- **Standardized IDs**: Document IDs use spaces instead of underscores (e.g., \"Health Act\" not \"Health_Act\")\n",
    "- **Unified Vector Search**: All chunks use the same vector index for cross-document search\n",
    "- **Two-Stage Search**: Combines vector similarity with reranking for improved relevance\n",
    "\n",
    "## Search Capabilities\n",
    "- Standard vector search using cosine similarity\n",
    "- Reranked search for improved relevance scoring\n",
    "- Optional retrieval of neighboring chunks for context\n",
    "- Combined search across different document types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-huggingface\n",
    "%pip install langchain-neo4j\n",
    "%pip install langchain\n",
    "%pip install langchain-text-splitters\n",
    "%pip install neo4j\n",
    "%pip install sentence-transformers\n",
    "%pip install python-dotenv\n",
    "%pip install numpy\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "import time\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reranking import\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Configure Environment and Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j connection settings\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\", \"\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE\n",
    ")\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=20, \n",
    "    tokens_per_chunk=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Remove all existing image nodes from the Neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all existing image nodes from the Neo4j database completely. \n",
    "def clean_neo4j_image_data():\n",
    "    # First, count how many nodes exist before deletion\n",
    "    count_query = \"\"\"\n",
    "    MATCH (c) \n",
    "    WHERE c:ImageChunk OR \n",
    "        (c:UpdatedChunksAndImagesv4 AND c.type = 'image')\n",
    "    RETURN count(c) as total_nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    count_result = graph.query(count_query)\n",
    "    initial_count = count_result[0][\"total_nodes\"] if count_result else 0\n",
    "    \n",
    "    print(f\"Found {initial_count} image nodes to remove...\")\n",
    "    \n",
    "    # Delete all image-related nodes with any label\n",
    "    cleanup_query = \"\"\"\n",
    "    MATCH (c) \n",
    "    WHERE c:ImageChunk OR \n",
    "        (c:UpdatedChunksAndImagesv4 AND c.type = 'image')\n",
    "    DETACH DELETE c\n",
    "    RETURN count(c) as removed_nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    result = graph.query(cleanup_query)\n",
    "    removed_count = result[0][\"removed_nodes\"] if result else 0\n",
    "    \n",
    "    # Verify all nodes were deleted\n",
    "    verify_query = \"\"\"\n",
    "    MATCH (c) \n",
    "    WHERE c:ImageChunk OR \n",
    "        (c:UpdatedChunksAndImagesv4 AND c.type = 'image')\n",
    "    RETURN count(c) as remaining_nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    verify_result = graph.query(verify_query)\n",
    "    remaining = verify_result[0][\"remaining_nodes\"] if verify_result else 0\n",
    "    \n",
    "    print(f\"Cleaned up Neo4j database: {removed_count} image nodes removed.\")\n",
    "    print(f\"Remaining image nodes: {remaining}\")\n",
    "    \n",
    "    if remaining > 0:\n",
    "        print(\"WARNING: Not all image nodes were removed. You may need to run cleanup again.\")\n",
    "    \n",
    "    return removed_count\n",
    "\n",
    "# comment out the following line to run the cleanup\n",
    "\n",
    "print(\"Beginning cleanup of existing image nodes...\")\n",
    "clean_neo4j_image_data()\n",
    "print(\"Cleanup completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Create Index in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index in Neo4j database for similarity search\n",
    "def setup_neo4j_indexes():\n",
    "    # Create constraint for unique ImageChunk IDs\n",
    "    graph.query(\"\"\"\n",
    "    CREATE CONSTRAINT IF NOT EXISTS FOR (c:ImageChunk) REQUIRE c.id IS UNIQUE\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create vector index for embeddings - use the standard chunk_embeddings name\n",
    "    graph.query(\"\"\"\n",
    "    CREATE VECTOR INDEX UpdatedChunksAndImagesv4 IF NOT EXISTS\n",
    "    FOR (m:UpdatedChunksAndImagesv4) \n",
    "    ON m.textEmbedding \n",
    "    OPTIONS { \n",
    "        indexConfig: { \n",
    "            `vector.dimensions`: 384, \n",
    "            `vector.similarity_function`: 'cosine'\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Neo4j indexes created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folder and file components from a path structure\n",
    "def extract_path_components(path: str) -> Dict[str, str]:\n",
    "    components = path.split('/')\n",
    "    if len(components) >= 2:\n",
    "        folder = components[0]\n",
    "        subfolder = components[1] if len(components) > 1 else None\n",
    "        filename = components[-1]\n",
    "    else:\n",
    "        folder = None\n",
    "        subfolder = None\n",
    "        filename = components[0]\n",
    "    \n",
    "    return {\n",
    "        \"folder\": folder, \n",
    "        \"subfolder\": subfolder,\n",
    "        \"filename\": filename\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse JSON file containing OCR data\n",
    "def process_json_file(file_path: str) -> Dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Create metadata for a chunk with updated structure\n",
    "def create_metadata(token_split_texts, folder, subfolder, filename):\n",
    "    chunks_with_metadata = []\n",
    "    chunk_seq_id = 0\n",
    "    \n",
    "    # Format subfolder name - replace underscores with spaces\n",
    "    display_subfolder = subfolder.replace(\"_\", \" \") if subfolder else \"\"\n",
    "    \n",
    "    # Create metadata for each chunk\n",
    "    for chunk in token_split_texts:\n",
    "        chunks_with_metadata.append({\n",
    "            'text': chunk,\n",
    "            'chunkSeqId': chunk_seq_id,\n",
    "            'chunkId': f'{folder}_{subfolder}_{filename}-chunk-{chunk_seq_id:04d}',\n",
    "            'folder': folder,\n",
    "            'subfolder': subfolder,\n",
    "            'file_name': filename,\n",
    "            'type': 'image',\n",
    "            'ImageUrl': f\"https://www.bclaws.gov.bc.ca/civix/document/id/complete/statreg/{filename}\"\n",
    "        })\n",
    "        \n",
    "        # Add specific ID based on folder type - use display_subfolder with spaces\n",
    "        if folder == \"Acts\":\n",
    "            chunks_with_metadata[-1][\"ActId\"] = display_subfolder\n",
    "        elif folder == \"Regulations\":\n",
    "            chunks_with_metadata[-1][\"RegId\"] = display_subfolder\n",
    "            \n",
    "        chunk_seq_id += 1\n",
    "        \n",
    "    return chunks_with_metadata\n",
    "\n",
    "# Create chunks from OCR text\n",
    "def create_chunks(ocr_text, folder, subfolder, filename):\n",
    "    # Use token_splitter directly on the full text\n",
    "    token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=20, tokens_per_chunk=256)\n",
    "    token_split_texts = token_splitter.split_text(ocr_text)\n",
    "    meta_data = create_metadata(token_split_texts, folder, subfolder, filename)    \n",
    "    return meta_data\n",
    "\n",
    "\n",
    "# Save chunk data to Neo4j with updated metadata and NEXT relationships\n",
    "def save_chunk_to_neo4j(chunk_id, text, metadata, embedding, previous_chunk_id=None):\n",
    "    # Base query for creating the ImageChunk node\n",
    "    query = \"\"\"\n",
    "    MERGE (c:ImageChunk:UpdatedChunksAndImagesv4 {id: $id})\n",
    "    SET c.text = $text,\n",
    "        c.textEmbedding = $embedding,\n",
    "        c.ImageUrl = $metadata.ImageUrl,\n",
    "        c.folder = $metadata.folder,\n",
    "        c.subfolder = $metadata.subfolder,\n",
    "        c.file_name = $metadata.file_name,\n",
    "        c.type = $metadata.type,\n",
    "        c.chunkSeqId = $metadata.chunkSeqId,\n",
    "        c.chunkId = $metadata.chunkId\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add ActId or RegId if present\n",
    "    if \"ActId\" in metadata:\n",
    "        query += \"\"\"\n",
    "        SET c.ActId = $metadata.ActId\n",
    "        \"\"\"\n",
    "    \n",
    "    if \"RegId\" in metadata:\n",
    "        query += \"\"\"\n",
    "        SET c.RegId = $metadata.RegId\n",
    "        \"\"\"\n",
    "    \n",
    "    # Add relationship to previous chunk if available\n",
    "    if previous_chunk_id:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MATCH (prev:ImageChunk {id: $prev_id})\n",
    "        MERGE (prev)-[:NEXT]->(c)\n",
    "        \"\"\"\n",
    "    \n",
    "    # Add conditional relationship creation based on folder type\n",
    "    if \"ActId\" in metadata:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (a:Act {name: $metadata.ActId})\n",
    "        MERGE (c)-[:PART_OF]->(a)\n",
    "        \"\"\"\n",
    "    elif \"RegId\" in metadata:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (r:Regulation {name: $metadata.RegId})\n",
    "        MERGE (c)-[:PART_OF]->(r)\n",
    "        \"\"\"\n",
    "    \n",
    "    query += \"\\nRETURN c\"\n",
    "    \n",
    "    result = graph.query(\n",
    "        query=query,\n",
    "        params={\n",
    "            \"text\": text,\n",
    "            \"embedding\": embedding,\n",
    "            \"metadata\": metadata,\n",
    "            \"prev_id\": previous_chunk_id\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Main Processing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all OCR data from the loaded JSON\n",
    "def process_ocr_data(data: Dict):\n",
    "    total_chunks = 0\n",
    "    \n",
    "    # Process the nested structure\n",
    "    for folder, subfolders in data.items():\n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        \n",
    "        for subfolder, files in subfolders.items():\n",
    "            print(f\"  Processing subfolder: {subfolder}\")\n",
    "            \n",
    "            for filename, ocr_text in files.items():\n",
    "                print(f\"    Processing file: {filename}\")\n",
    "                \n",
    "                # Replace line breaks with spaces for better readability\n",
    "                ocr_text = ocr_text.replace('\\n', ' ')\n",
    "                \n",
    "                # Create chunks using the new function\n",
    "                chunks_with_metadata = create_chunks(ocr_text, folder, subfolder, filename)\n",
    "                \n",
    "                # Process each chunk and save to Neo4j\n",
    "                previous_chunk_id = None\n",
    "                \n",
    "                for chunk_data in chunks_with_metadata:\n",
    "                    # Create embedding\n",
    "                    embedding = embedding_model.embed_query(chunk_data['text'])\n",
    "                    \n",
    "                    # Save to Neo4j with NEXT relationship to previous chunk\n",
    "                    save_chunk_to_neo4j(\n",
    "                        chunk_id=chunk_data['chunkId'],\n",
    "                        text=chunk_data['text'],\n",
    "                        metadata=chunk_data,\n",
    "                        embedding=embedding,\n",
    "                        previous_chunk_id=previous_chunk_id\n",
    "                    )\n",
    "                    \n",
    "                    previous_chunk_id = chunk_data['chunkId']\n",
    "                    total_chunks += 1\n",
    "    \n",
    "    print(f\"Completed processing. Total chunks created: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution function\n",
    "def main():\n",
    "    # Setup Neo4j indexes\n",
    "    setup_neo4j_indexes()\n",
    "    \n",
    "    # Specify path to your JSON file\n",
    "    json_file_path = \"./final_image_sonnet.json\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(json_file_path):\n",
    "        print(f\"ERROR: File '{json_file_path}' not found. Please check the path.\")\n",
    "        return\n",
    "    \n",
    "    # Process the OCR data\n",
    "    print(f\"Loading data from {json_file_path}...\")\n",
    "    data = process_json_file(json_file_path)\n",
    "    \n",
    "    # Verify data was loaded\n",
    "    if not data:\n",
    "        print(\"ERROR: No data loaded from the JSON file.\")\n",
    "        return\n",
    "    \n",
    "    # Process the data\n",
    "    start_time = time.time()\n",
    "    process_ocr_data(data)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Processing completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Run the main function to process and index all data\n",
    "print(\"Starting main processing...\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Neo4j Node Label Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Cypher query to consolidate node labels for unified vector search\n",
    "def execute_label_consolidation():\n",
    "    # Consolidate UpdatedChunk nodes\n",
    "    updated_chunk_query = \"\"\"\n",
    "    MATCH (m:UpdatedChunk) \n",
    "    WHERE NOT m:UpdatedChunksAndImagesv4\n",
    "    SET m:UpdatedChunksAndImagesv4\n",
    "    RETURN count(m) as updated_chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consolidate ImageChunk nodes\n",
    "    image_chunk_query = \"\"\"\n",
    "    MATCH (m:ImageChunk) \n",
    "    WHERE NOT m:UpdatedChunksAndImagesv4\n",
    "    SET m:UpdatedChunksAndImagesv4\n",
    "    RETURN count(m) as updated_image_chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute both queries\n",
    "    updated_chunks_result = graph.query(updated_chunk_query)\n",
    "    image_chunks_result = graph.query(image_chunk_query)\n",
    "    \n",
    "    # Extract counts\n",
    "    updated_chunks_count = updated_chunks_result[0]['updated_chunks'] if updated_chunks_result else 0\n",
    "    image_chunks_count = image_chunks_result[0]['updated_image_chunks'] if image_chunks_result else 0\n",
    "    \n",
    "    print(f\"Consolidated {updated_chunks_count} UpdatedChunk nodes\")\n",
    "    print(f\"Consolidated {image_chunks_count} ImageChunk nodes\")\n",
    "    print(f\"Total nodes consolidated: {updated_chunks_count + image_chunks_count}\")\n",
    "    \n",
    "    # Verify the consolidation\n",
    "    verification_query = \"\"\"\n",
    "    MATCH (n:UpdatedChunksAndImagesv4)\n",
    "    RETURN count(n) as consolidated_nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    verification_result = graph.query(verification_query)\n",
    "    total_consolidated = verification_result[0]['consolidated_nodes'] if verification_result else 0\n",
    "    \n",
    "    print(f\"Total nodes with UpdatedChunksAndImagesv4 label: {total_consolidated}\")\n",
    "    \n",
    "    return {\n",
    "        \"updated_chunks\": updated_chunks_count,\n",
    "        \"image_chunks\": image_chunks_count,\n",
    "        \"total_consolidated\": total_consolidated\n",
    "    }\n",
    "\n",
    "# Execute the consolidation\n",
    "consolidation_results = execute_label_consolidation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Neo4j Node Creation Verification Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_processing():\n",
    "    # Check for ImageChunk nodes\n",
    "    image_query = \"\"\"\n",
    "    MATCH (c:ImageChunk)\n",
    "    RETURN count(c) as image_count\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for specific properties\n",
    "    properties_query = \"\"\"\n",
    "    MATCH (c:ImageChunk)\n",
    "    WHERE c.ActId IS NOT NULL OR c.RegId IS NOT NULL\n",
    "    RETURN count(c) as doc_count\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check for NEXT relationships\n",
    "    next_query = \"\"\"\n",
    "    MATCH (c1:ImageChunk)-[:NEXT]->(c2:ImageChunk)\n",
    "    RETURN count(c1) as relationship_count\n",
    "    \"\"\"\n",
    "    \n",
    "    image_result = graph.query(image_query)\n",
    "    properties_result = graph.query(properties_query)\n",
    "    next_result = graph.query(next_query)\n",
    "    \n",
    "    image_count = image_result[0][\"image_count\"] if image_result else 0\n",
    "    doc_count = properties_result[0][\"doc_count\"] if properties_result else 0\n",
    "    rel_count = next_result[0][\"relationship_count\"] if next_result else 0\n",
    "    \n",
    "    print(f\"ImageChunk nodes: {image_count}\")\n",
    "    print(f\"Nodes with ActId/RegId: {doc_count}\")\n",
    "    print(f\"NEXT relationships: {rel_count}\")\n",
    "    \n",
    "    return {\n",
    "        \"image_count\": image_count,\n",
    "        \"doc_count\": doc_count,\n",
    "        \"rel_count\": rel_count\n",
    "    }\n",
    "\n",
    "# Run verification\n",
    "verification = verify_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Neo4j Test Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for similar chunks with related chunks via NEXT relationship\n",
    "def search_similar_chunks(query_text: str, top_k: int = 5, include_related: bool = True):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "    \n",
    "    # Search in Neo4j using vector index\n",
    "    search_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('UpdatedChunksAndImagesv4', $top_k, $textEmbedding)\n",
    "    YIELD node, score\n",
    "    \"\"\"\n",
    "    \n",
    "    if include_related:\n",
    "        search_query += \"\"\"\n",
    "        WITH node, score\n",
    "        OPTIONAL MATCH (node)<-[:NEXT]-(prev:ImageChunk)\n",
    "        OPTIONAL MATCH (node)-[:NEXT]->(next:ImageChunk)\n",
    "        \"\"\"\n",
    "    \n",
    "    search_query += \"\"\"\n",
    "    RETURN \n",
    "        node.id as id,\n",
    "        node.ImageUrl as ImageUrl,\n",
    "        node.text as text,\n",
    "        node.type as type,\n",
    "        node.folder as folder,\n",
    "        node.subfolder as subfolder,\n",
    "        node.file_name as file_name,\n",
    "        node.chunkSeqId as chunkSeqId,\n",
    "        score,\n",
    "    \"\"\"\n",
    "    \n",
    "    if include_related:\n",
    "        search_query += \"\"\"\n",
    "        prev.text as prev_text,\n",
    "        prev.id as prev_id,\n",
    "        next.text as next_text,\n",
    "        next.id as next_id,\n",
    "        \"\"\"\n",
    "    \n",
    "    search_query += \"\"\"\n",
    "        CASE \n",
    "            WHEN node.ActId IS NOT NULL THEN {type: 'Act', id: node.ActId}\n",
    "            WHEN node.RegId IS NOT NULL THEN {type: 'Regulation', id: node.RegId}\n",
    "            ELSE null\n",
    "        END as related_document\n",
    "    ORDER BY score DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    results = graph.query(\n",
    "        query=search_query,\n",
    "        params={\"textEmbedding\": query_embedding, \"top_k\": top_k}\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Two-stage search with vector similarity followed by reranking, including related chunks\n",
    "def reranked_search(query_text: str, top_k: int = 5, candidates: int = 20, include_related: bool = True):\n",
    "    # Load the reranking model\n",
    "    reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "    \n",
    "    # First stage: Retrieve candidates with vector search\n",
    "    initial_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('UpdatedChunksAndImagesv4', $candidates, $textEmbedding)\n",
    "    YIELD node, score\n",
    "    \"\"\"\n",
    "    \n",
    "    if include_related:\n",
    "        initial_query += \"\"\"\n",
    "        WITH node, score\n",
    "        OPTIONAL MATCH (node)<-[:NEXT]-(prev:ImageChunk)\n",
    "        OPTIONAL MATCH (node)-[:NEXT]->(next:ImageChunk)\n",
    "        \"\"\"\n",
    "    \n",
    "    initial_query += \"\"\"\n",
    "    RETURN \n",
    "        node.id as id,\n",
    "        node.text as text,\n",
    "        node.folder as folder,\n",
    "        node.subfolder as subfolder,\n",
    "        node.file_name as file_name,\n",
    "        node.type as type,\n",
    "        node.ImageUrl as ImageUrl,\n",
    "        node.chunkSeqId as chunkSeqId,\n",
    "        score as vector_score,\n",
    "    \"\"\"\n",
    "    \n",
    "    if include_related:\n",
    "        initial_query += \"\"\"\n",
    "        prev.text as prev_text,\n",
    "        prev.id as prev_id,\n",
    "        next.text as next_text,\n",
    "        next.id as next_id,\n",
    "        \"\"\"\n",
    "    \n",
    "    initial_query += \"\"\"\n",
    "        CASE \n",
    "            WHEN node.ActId IS NOT NULL THEN {type: 'Act', id: node.ActId}\n",
    "            WHEN node.RegId IS NOT NULL THEN {type: 'Regulation', id: node.RegId}\n",
    "            ELSE null\n",
    "        END as related_document\n",
    "    \"\"\"\n",
    "    \n",
    "    candidate_results = graph.query(\n",
    "        query=initial_query,\n",
    "        params={\"textEmbedding\": query_embedding, \"candidates\": candidates}\n",
    "    )\n",
    "    \n",
    "    # Second stage: Rerank candidates\n",
    "    if candidate_results:\n",
    "        # Create pairs of (query, text) for reranking\n",
    "        pairs = [(query_text, result[\"text\"]) for result in candidate_results]\n",
    "        \n",
    "        # Score candidate pairs with reranker model\n",
    "        reranker_scores = reranker.predict(pairs)\n",
    "        \n",
    "        # Add reranker scores to results\n",
    "        for i, result in enumerate(candidate_results):\n",
    "            result[\"reranker_score\"] = float(reranker_scores[i])\n",
    "        \n",
    "        # Sort by reranker score (descending)\n",
    "        reranked_results = sorted(candidate_results, key=lambda x: x[\"reranker_score\"], reverse=True)\n",
    "        \n",
    "        # Return top_k results\n",
    "        return reranked_results[:top_k]\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Neo4j Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different search methods without processing data.\n",
    "def test_rerankers():\n",
    "    # Test the standard vector search.\n",
    "    query = \"What does the official coat of arms of BC look like?\"\n",
    "    \n",
    "    print(\"\\nStandard Vector Search:\")\n",
    "    vector_results = search_similar_chunks(query, top_k=10)\n",
    "    for result in vector_results:\n",
    "        print(f\"Score: {result['score']:.4f}\")\n",
    "        print(f\"Document: {result['folder']}/{result['subfolder']}/{result['file_name']}\")\n",
    "        print(f\"ID: {result['id']}\")\n",
    "        print(f\"ChunkSeqId: {result['chunkSeqId']}\")\n",
    "        print(f\"Text: {result['text'][:100]}...\\n\")\n",
    "        \n",
    "        if 'prev_text' in result and result['prev_text']:\n",
    "            print(f\"Previous chunk: {result['prev_text'][:50]}...\\n\")\n",
    "        \n",
    "        if 'next_text' in result and result['next_text']:\n",
    "            print(f\"Next chunk: {result['next_text'][:50]}...\\n\")\n",
    "    \n",
    "    # Test the reranked search.\n",
    "    print(\"\\nReranked Search:\")\n",
    "    rerank_results = reranked_search(query, top_k=3)\n",
    "    for result in rerank_results:\n",
    "        print(f\"Score: {result['reranker_score']:.4f}\")\n",
    "        print(f\"Document: {result['folder']}/{result['subfolder']}/{result['file_name']}\")\n",
    "        print(f\"ID: {result['id']}\")\n",
    "        print(f\"ChunkSeqId: {result['chunkSeqId']}\")\n",
    "        print(f\"Text: {result['text'][:100]}...\\n\")\n",
    "        \n",
    "        if 'prev_text' in result and result['prev_text']:\n",
    "            print(f\"Previous chunk: {result['prev_text'][:50]}...\\n\")\n",
    "        \n",
    "        if 'next_text' in result and result['next_text']:\n",
    "            print(f\"Next chunk: {result['next_text'][:50]}...\\n\")\n",
    "            \n",
    "test_rerankers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
