{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Image Processing and Vector Search\n",
    "\n",
    "## Overview\n",
    "This notebook processes OCR (Optical Character Recognition) data extracted from images and indexes them in Neo4j for semantic search. The OCR text comes from a structured JSON file containing descriptions of various images from legal documents.\n",
    "\n",
    "## Workflow\n",
    "1. **Data Loading**: Loads OCR text data from a nested JSON structure\n",
    "2. **Text Processing**: Extracts sections from structured OCR text\n",
    "3. **Chunking**: Splits sections into manageable text chunks\n",
    "4. **Embedding Generation**: Creates vector embeddings using all-MiniLM-L6-v2\n",
    "5. **Neo4j Storage**: Stores chunks as ImageChunk nodes with proper metadata\n",
    "6. **Relationship Creation**: Establishes relationships between chunks and document types\n",
    "7. **Vector Search**: Enables semantic search across all image descriptions\n",
    "8. **Reranking**: Improves search relevance using a cross-encoder reranking model\n",
    "\n",
    "## Data Structure\n",
    "The OCR data follows a hierarchical structure:\n",
    "- Folder (e.g., Acts, Regulations)\n",
    "  - Subfolder (e.g., Election_Act)\n",
    "    - File (e.g., 96106_greatseal.gif)\n",
    "      - OCR Text with sections like \"Image Type and Category\", \"Detailed Description\", etc.\n",
    "\n",
    "## Neo4j Schema\n",
    "- **Node Labels**: \n",
    "  - `ImageChunk`: Contains text chunks from OCR data\n",
    "  - `UpdatedChunksAndImagesv4`: Combined label for unified vector search\n",
    "  - Document types: `Act`, `Regulation`, etc.\n",
    "- **Relationships**: \n",
    "  - `(ImageChunk)-[:PART_OF]->(DocumentType)`\n",
    "- **Vector Index**: On the `textEmbedding` property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-huggingface\n",
    "%pip install langchain-neo4j\n",
    "%pip install langchain\n",
    "%pip install langchain-text-splitters\n",
    "%pip install neo4j\n",
    "%pip install sentence-transformers\n",
    "%pip install python-dotenv\n",
    "%pip install numpy\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "import time\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Reranking import\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Configure Environment and Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Neo4j connection settings\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\", \"\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE\n",
    ")\n",
    "\n",
    "# Initialize embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=20, \n",
    "    tokens_per_chunk=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Create Index in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index in Neo4j database for similarity search\n",
    "def setup_neo4j_indexes():\n",
    "    # Create constraint for unique ImageChunk IDs\n",
    "    graph.query(\"\"\"\n",
    "    CREATE CONSTRAINT IF NOT EXISTS FOR (c:ImageChunk) REQUIRE c.id IS UNIQUE\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create vector index for embeddings - use the standard chunk_embeddings name\n",
    "    graph.query(\"\"\"\n",
    "    CREATE VECTOR INDEX UpdatedChunksAndImagesv4 IF NOT EXISTS\n",
    "    FOR (m:UpdatedChunksAndImagesv4) \n",
    "    ON m.textEmbedding \n",
    "    OPTIONS { \n",
    "        indexConfig: { \n",
    "            `vector.dimensions`: 384, \n",
    "            `vector.similarity_function`: 'cosine'\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"Neo4j indexes created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folder and file components from a path structure\n",
    "def extract_path_components(path: str) -> Dict[str, str]:\n",
    "    components = path.split('/')\n",
    "    if len(components) >= 2:\n",
    "        folder = components[0]\n",
    "        subfolder = components[1] if len(components) > 1 else None\n",
    "        filename = components[-1]\n",
    "    else:\n",
    "        folder = None\n",
    "        subfolder = None\n",
    "        filename = components[0]\n",
    "    \n",
    "    return {\n",
    "        \"folder\": folder, \n",
    "        \"subfolder\": subfolder,\n",
    "        \"filename\": filename\n",
    "    }\n",
    "\n",
    "# Extract sections from OCR text based on numbered headers\n",
    "def extract_sections(text: str) -> Dict[str, str]:\n",
    "    sections = {}\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    current_section = None\n",
    "    current_content = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Check for section headers like \"1. Image Type and Category:\"\n",
    "        if any(line.startswith(f\"{i}. \") for i in range(1, 7)):\n",
    "            # Save previous section if exists\n",
    "            if current_section:\n",
    "                sections[current_section] = '\\n'.join(current_content).strip()\n",
    "            \n",
    "            # Start new section\n",
    "            current_section = line\n",
    "            current_content = []\n",
    "        else:\n",
    "            # Add line to current section content\n",
    "            if current_section:\n",
    "                current_content.append(line)\n",
    "    \n",
    "    # Add the last section\n",
    "    if current_section and current_content:\n",
    "        sections[current_section] = '\\n'.join(current_content).strip()\n",
    "    \n",
    "    # If there's a \"Detailed Description\" section\n",
    "    detailed_idx = next((i for i, line in enumerate(lines) if \"Detailed Description:\" in line), -1)\n",
    "    if detailed_idx >= 0:\n",
    "        detailed_text = '\\n'.join(lines[detailed_idx+1:]).strip()\n",
    "        sections[\"Detailed Description:\"] = detailed_text\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Document Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse JSON file containing OCR data\n",
    "def process_json_file(file_path: str) -> Dict:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Create metadata for a chunk with updated structure\n",
    "def create_metadata(\n",
    "    folder: str, \n",
    "    subfolder: str, \n",
    "    filename: str, \n",
    "    section_name: str\n",
    ") -> Dict[str, Any]:\n",
    "    # Base metadata\n",
    "    metadata = {\n",
    "        \"folder\": folder,\n",
    "        \"subfolder\": subfolder,\n",
    "        \"file_name\": filename,\n",
    "        \"type\": \"image\",\n",
    "        \"section\": section_name,\n",
    "        \"url\": f\"https://www.bclaws.gov.bc.ca/civix/document/id/complete/statreg/{filename}\"\n",
    "    }\n",
    "    \n",
    "    # Add specific ID based on folder type\n",
    "    if folder == \"Acts\":\n",
    "        metadata[\"ActId\"] = subfolder\n",
    "    elif folder == \"Regulations\":\n",
    "        metadata[\"RegId\"] = subfolder\n",
    "    elif folder == \"Appendix\":\n",
    "        metadata[\"AppendixId\"] = subfolder\n",
    "    elif folder == \"Others\":\n",
    "        metadata[\"OthersId\"] = subfolder\n",
    "    elif folder == \"Schedules\":\n",
    "        metadata[\"SchedulesId\"] = subfolder\n",
    "    elif folder == \"Point_in_Times\":\n",
    "        metadata[\"PointInTimeId\"] = subfolder\n",
    "    elif folder == \"Parts\":\n",
    "        metadata[\"PartsId\"] = subfolder\n",
    "    elif folder == \"Rules\":\n",
    "        metadata[\"RulesId\"] = subfolder\n",
    "        \n",
    "    return metadata\n",
    "\n",
    "# Create embedding for a chunk with given text and metadata\n",
    "def create_chunk_embedding(text: str, metadata: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    embedding = embedding_model.embed_query(text)\n",
    "    \n",
    "    # Create a unique ID based on metadata\n",
    "    chunk_id = f\"{metadata['folder']}_{metadata['subfolder']}_{metadata['file_name']}_{metadata['section']}\"\n",
    "    chunk_id = chunk_id.replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    \n",
    "    return {\n",
    "        \"id\": chunk_id,\n",
    "        \"text\": text,\n",
    "        \"metadata\": metadata,\n",
    "        \"embedding\": embedding\n",
    "    }\n",
    "\n",
    "# Save chunk data to Neo4j with updated metadata and relationships\n",
    "def save_chunk_to_neo4j(chunk_data: Dict[str, Any]):\n",
    "    # Base query for creating the ImageChunk node\n",
    "    query = \"\"\"\n",
    "    MERGE (c:ImageChunk {id: $id})\n",
    "    SET c.text = $text,\n",
    "        c.textEmbedding = $textEmbedding,\n",
    "        c.url = $metadata.url,\n",
    "        c.folder = $metadata.folder,\n",
    "        c.subfolder = $metadata.subfolder,\n",
    "        c.file_name = $metadata.file_name,\n",
    "        c.type = $metadata.type,\n",
    "        c.section = $metadata.section\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add conditional relationship creation based on folder type\n",
    "    if \"ActId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (a:Act {name: $metadata.ActId})\n",
    "        MERGE (c)-[:PART_OF]->(a)\n",
    "        \"\"\"\n",
    "    elif \"RegId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (r:Regulation {name: $metadata.RegId})\n",
    "        MERGE (c)-[:PART_OF]->(r)\n",
    "        \"\"\"\n",
    "    elif \"AppendixId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (ap:Appendix {name: $metadata.AppendixId})\n",
    "        MERGE (c)-[:PART_OF]->(ap)\n",
    "        \"\"\"\n",
    "    elif \"OthersId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (o:Other {name: $metadata.OthersId})\n",
    "        MERGE (c)-[:PART_OF]->(o)\n",
    "        \"\"\"\n",
    "    elif \"SchedulesId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (s:Schedule {name: $metadata.SchedulesId})\n",
    "        MERGE (c)-[:PART_OF]->(s)\n",
    "        \"\"\"\n",
    "    elif \"PointInTimeId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (p:PointInTime {name: $metadata.PointInTimeId})\n",
    "        MERGE (c)-[:PART_OF]->(p)\n",
    "        \"\"\"\n",
    "    elif \"PartsId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (p:Part {name: $metadata.PartsId})\n",
    "        MERGE (c)-[:PART_OF]->(p)\n",
    "        \"\"\"\n",
    "    elif \"RulesId\" in chunk_data[\"metadata\"]:\n",
    "        query += \"\"\"\n",
    "        WITH c\n",
    "        MERGE (r:Rule {name: $metadata.RulesId})\n",
    "        MERGE (c)-[:PART_OF]->(r)\n",
    "        \"\"\"\n",
    "    \n",
    "    query += \"\\nRETURN c\"\n",
    "    \n",
    "    result = graph.query(\n",
    "        query=query,\n",
    "        params={\n",
    "            \"id\": chunk_data[\"id\"],\n",
    "            \"text\": chunk_data[\"text\"],\n",
    "            \"textEmbedding\": chunk_data[\"embedding\"],\n",
    "            \"metadata\": chunk_data[\"metadata\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Main Processing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all OCR data from the loaded JSON\n",
    "def process_ocr_data(data: Dict):\n",
    "    total_chunks = 0\n",
    "    \n",
    "    # Process the nested structure\n",
    "    for folder, subfolders in data.items():\n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        \n",
    "        for subfolder, files in subfolders.items():\n",
    "            print(f\"  Processing subfolder: {subfolder}\")\n",
    "            \n",
    "            for filename, ocr_text in files.items():\n",
    "                print(f\"    Processing file: {filename}\")\n",
    "                \n",
    "                # Extract sections from the OCR text\n",
    "                sections = extract_sections(ocr_text)\n",
    "                \n",
    "                # Process each section\n",
    "                for section_name, section_content in sections.items():\n",
    "                    # Create chunks from the section text\n",
    "                    chunks = text_splitter.split_text(section_content)\n",
    "                    \n",
    "                    for chunk in chunks:\n",
    "                        # Create metadata\n",
    "                        metadata = create_metadata(\n",
    "                            folder=folder,\n",
    "                            subfolder=subfolder,\n",
    "                            filename=filename,\n",
    "                            section_name=section_name\n",
    "                        )\n",
    "                        \n",
    "                        # Create embedding\n",
    "                        chunk_data = create_chunk_embedding(\n",
    "                            text=chunk,\n",
    "                            metadata=metadata\n",
    "                        )\n",
    "                        \n",
    "                        # Save to Neo4j\n",
    "                        save_chunk_to_neo4j(chunk_data)\n",
    "                        total_chunks += 1\n",
    "    \n",
    "    print(f\"Completed processing. Total chunks created: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution function\n",
    "def main():\n",
    "    # Setup Neo4j indexes\n",
    "    setup_neo4j_indexes()\n",
    "    \n",
    "    # Specify path to your JSON file\n",
    "    json_file_path = \"./final_image_sonnet.json\"\n",
    "    \n",
    "    # Process the OCR data\n",
    "    print(f\"Loading data from {json_file_path}...\")\n",
    "    data = process_json_file(json_file_path)\n",
    "    \n",
    "    # Process the data\n",
    "    start_time = time.time()\n",
    "    process_ocr_data(data)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Processing completed in {end_time - start_time:.2f} seconds.\")\n",
    "# Run the main function when executing the notebook\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Neo4j Node Label Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Cypher query to consolidate node labels for unified vector search\n",
    "def execute_label_consolidation():\n",
    "    \"\"\"\n",
    "    Consolidate existing nodes under a unified label (UpdatedChunksAndImagesv4) \n",
    "    to ensure all nodes are accessible through the same vector index.\n",
    "    \"\"\"\n",
    "    # Consolidate UpdatedChunk nodes\n",
    "    updated_chunk_query = \"\"\"\n",
    "    MATCH (m:UpdatedChunk) \n",
    "    WHERE NOT m:UpdatedChunksAndImagesv4\n",
    "    SET m:UpdatedChunksAndImagesv4\n",
    "    RETURN count(m) as updated_chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Consolidate ImageChunk nodes\n",
    "    image_chunk_query = \"\"\"\n",
    "    MATCH (m:ImageChunk) \n",
    "    WHERE NOT m:UpdatedChunksAndImagesv4\n",
    "    SET m:UpdatedChunksAndImagesv4\n",
    "    RETURN count(m) as updated_image_chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute both queries\n",
    "    updated_chunks_result = graph.query(updated_chunk_query)\n",
    "    image_chunks_result = graph.query(image_chunk_query)\n",
    "    \n",
    "    # Extract counts\n",
    "    updated_chunks_count = updated_chunks_result[0]['updated_chunks'] if updated_chunks_result else 0\n",
    "    image_chunks_count = image_chunks_result[0]['updated_image_chunks'] if image_chunks_result else 0\n",
    "    \n",
    "    print(f\"Consolidated {updated_chunks_count} UpdatedChunk nodes\")\n",
    "    print(f\"Consolidated {image_chunks_count} ImageChunk nodes\")\n",
    "    print(f\"Total nodes consolidated: {updated_chunks_count + image_chunks_count}\")\n",
    "    \n",
    "    # Verify the consolidation\n",
    "    verification_query = \"\"\"\n",
    "    MATCH (n:UpdatedChunksAndImagesv4)\n",
    "    RETURN count(n) as consolidated_nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    verification_result = graph.query(verification_query)\n",
    "    total_consolidated = verification_result[0]['consolidated_nodes'] if verification_result else 0\n",
    "    \n",
    "    print(f\"Total nodes with UpdatedChunksAndImagesv4 label: {total_consolidated}\")\n",
    "    \n",
    "    return {\n",
    "        \"updated_chunks\": updated_chunks_count,\n",
    "        \"image_chunks\": image_chunks_count,\n",
    "        \"total_consolidated\": total_consolidated\n",
    "    }\n",
    "\n",
    "# Execute the consolidation\n",
    "consolidation_results = execute_label_consolidation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Neo4j Test Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for similar chunks based on the query text with updated metadata fields\n",
    "def search_similar_chunks(query_text: str, top_k: int = 5):\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "    \n",
    "    # Search in Neo4j using the common index name\n",
    "    search_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('UpdatedChunksAndImagesv4', $top_k, $textEmbedding)\n",
    "    YIELD node, score\n",
    "    RETURN \n",
    "        node.id as id,\n",
    "        node.url as url,\n",
    "        node.text as text,\n",
    "        node.section as section,\n",
    "        node.file_name as file_name,\n",
    "        node.type as type,\n",
    "        node.folder as folder,\n",
    "        node.subfolder as subfolder,\n",
    "        score,\n",
    "        CASE \n",
    "            WHEN node.ActId IS NOT NULL THEN {type: 'Act', id: node.ActId}\n",
    "            WHEN node.RegId IS NOT NULL THEN {type: 'Regulation', id: node.RegId}\n",
    "            WHEN node.AppendixId IS NOT NULL THEN {type: 'Appendix', id: node.AppendixId}\n",
    "            WHEN node.OthersId IS NOT NULL THEN {type: 'Other', id: node.OthersId}\n",
    "            WHEN node.SchedulesId IS NOT NULL THEN {type: 'Schedule', id: node.SchedulesId}\n",
    "            WHEN node.PointInTimeId IS NOT NULL THEN {type: 'PointInTime', id: node.PointInTimeId}\n",
    "            WHEN node.PartsId IS NOT NULL THEN {type: 'Part', id: node.PartsId}\n",
    "            WHEN node.RulesId IS NOT NULL THEN {type: 'Rule', id: node.RulesId}\n",
    "            ELSE null\n",
    "        END as related_document\n",
    "    ORDER BY score DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    results = graph.query(\n",
    "        query=search_query,\n",
    "        params={\"textEmbedding\": query_embedding, \"top_k\": top_k}\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Two-stage search with vector similarity followed by reranking.\n",
    "def reranked_search(query_text: str, top_k: int = 5, candidates: int = 20):\n",
    "    # Load the reranking model\n",
    "    reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    \n",
    "    # Generate embedding for the query\n",
    "    query_embedding = embedding_model.embed_query(query_text)\n",
    "    \n",
    "    # First stage: Retrieve candidates with vector search - use the standard index name\n",
    "    initial_query = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('UpdatedChunksAndImagesv4', $candidates, $textEmbedding)\n",
    "    YIELD node, score\n",
    "    RETURN \n",
    "        node.id as id,\n",
    "        node.text as text,\n",
    "        node.section as section,\n",
    "        node.file_name as file_name,\n",
    "        node.type as type,\n",
    "        node.folder as folder,\n",
    "        node.subfolder as subfolder,\n",
    "        node.url as url,\n",
    "        score as vector_score,\n",
    "        CASE \n",
    "            WHEN node.ActId IS NOT NULL THEN {type: 'Act', id: node.ActId}\n",
    "            WHEN node.RegId IS NOT NULL THEN {type: 'Regulation', id: node.RegId}\n",
    "            WHEN node.AppendixId IS NOT NULL THEN {type: 'Appendix', id: node.AppendixId}\n",
    "            WHEN node.OthersId IS NOT NULL THEN {type: 'Other', id: node.OthersId}\n",
    "            WHEN node.SchedulesId IS NOT NULL THEN {type: 'Schedule', id: node.SchedulesId}\n",
    "            WHEN node.PointInTimeId IS NOT NULL THEN {type: 'PointInTime', id: node.PointInTimeId}\n",
    "            WHEN node.PartsId IS NOT NULL THEN {type: 'Part', id: node.PartsId}\n",
    "            WHEN node.RulesId IS NOT NULL THEN {type: 'Rule', id: node.RulesId}\n",
    "            ELSE null\n",
    "        END as related_document\n",
    "    \"\"\"\n",
    "    \n",
    "    candidate_results = graph.query(\n",
    "        query=initial_query,\n",
    "        params={\"textEmbedding\": query_embedding, \"candidates\": candidates}\n",
    "    )\n",
    "    \n",
    "    # Second stage: Rerank candidates\n",
    "    if candidate_results:\n",
    "        # Create pairs of (query, text) for reranking\n",
    "        pairs = [(query_text, result[\"text\"]) for result in candidate_results]\n",
    "        \n",
    "        # Score candidate pairs with reranker model\n",
    "        reranker_scores = reranker.predict(pairs)\n",
    "        \n",
    "        # Add reranker scores to results\n",
    "        for i, result in enumerate(candidate_results):\n",
    "            result[\"reranker_score\"] = float(reranker_scores[i])\n",
    "        \n",
    "        # Sort by reranker score (descending)\n",
    "        reranked_results = sorted(candidate_results, key=lambda x: x[\"reranker_score\"], reverse=True)\n",
    "        \n",
    "        # Return top_k results\n",
    "        return reranked_results[:top_k]\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Neo4j Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rerankers():\n",
    "    \"\"\"Test different search methods without processing data.\"\"\"\n",
    "    query = \"What does the official coat of arms of BC look like?\"\n",
    "    \n",
    "    print(\"\\nStandard Vector Search:\")\n",
    "    vector_results = search_similar_chunks(query, top_k=10)\n",
    "    for result in vector_results:\n",
    "        print(f\"Score: {result['score']:.4f}\")\n",
    "        print(f\"Document: {result['folder']}/{result['subfolder']}/{result['file_name']}\")\n",
    "        print(f\"Section: {result['section']}\")\n",
    "        print(f\"Text: {result['text'][:100]}...\\n\")\n",
    "    \n",
    "    print(\"\\nReranked Search:\")\n",
    "    rerank_results = reranked_search(query, top_k=3)\n",
    "    for result in rerank_results:\n",
    "        print(f\"Score: {result['reranker_score']:.4f}\")\n",
    "        print(f\"Document: {result['folder']}/{result['subfolder']}/{result['file_name']}\")\n",
    "        print(f\"Section: {result['section']}\")\n",
    "        print(f\"Text: {result['text'][:100]}...\\n\")\n",
    "        \n",
    "# Run just the search tests without processing data\n",
    "test_rerankers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
