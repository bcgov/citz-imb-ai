{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9ee45c7",
   "metadata": {},
   "source": [
    "# Lesson 1 - Getting started with Embeddings\n",
    "In this lesson we will be using the B.C law titles, sentence transformer as our embedding model and Postgres PGVector to store the embeddings. We will be using the embeddings to find similar sentences in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community\n",
    "%pip install boto3\n",
    "%pip install sentence_transformers\n",
    "%pip install psycopg2-binary\n",
    "%pip install pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b8ea2-80be-4396-952c-6c2ca2d4d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the migration\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.pgvector import PGVector\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from utility.getlawtitles import downloadlawtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536eae0-66da-4169-9b69-bb4338ec7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "POSTGRES_DB = os.getenv('POSTGRES_DB')\n",
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT')\n",
    "POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "\n",
    "CONNECTION_STRING = f'postgresql+psycopg2://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92630bfa-9ca7-433e-9364-49a88068a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "##################### EXAMPLE EMBEDDINGS ############################\n",
    "# Get embedding data for PGVector\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Example transformation\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "doc_result = embeddings.embed_documents([text, \"This is not a test document.\"])\n",
    "print(query_result)\n",
    "print(doc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd4c7e",
   "metadata": {},
   "source": [
    "#### Download the law titles from S3  bucket. \n",
    "\n",
    "You will need to set the S3 access environment variables to download the data. If running locally, set these in `.docker/.env` before launching the `jupyter_notebook` container.\n",
    "```bash\n",
    "      - S3_ACCESS_KEY\n",
    "      - S3_SECRET_ACCESS_KEY\n",
    "      - S3_ENDPOINT_URL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ca6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "def downloadlawtitles():\n",
    "    S3_ACCESS_KEY = os.getenv('S3_ACCESS_KEY')\n",
    "    S3_SECRET_ACCESS_KEY = os.getenv('S3_SECRET_ACCESS_KEY')\n",
    "    S3_ENDPOINT_URL = os.getenv('S3_ENDPOINT_URL')\n",
    "\n",
    "    linode_obj_config = {\n",
    "        \"aws_access_key_id\": S3_ACCESS_KEY,\n",
    "        \"aws_secret_access_key\": S3_SECRET_ACCESS_KEY,\n",
    "        \"endpoint_url\": S3_ENDPOINT_URL,\n",
    "    }\n",
    "    bucket_name = \"IMBAIPilot\"\n",
    "\n",
    "    prefix = \"bclaws/data/txt/all_act_titles.txt\"\n",
    "\n",
    "    client = boto3.client(\"s3\", **linode_obj_config)\n",
    "\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "    BASE_PATH = \"DB/RawBCLaws/\"\n",
    "    count = 0\n",
    "\n",
    "    if not os.path.exists(BASE_PATH): os.makedirs(BASE_PATH, mode=0o777)\n",
    "\n",
    "    for page in pages:\n",
    "        for obj in page['Contents']:\n",
    "            newpath = os.path.join(BASE_PATH, obj['Key'].split('/')[-1])\n",
    "            count +=1\n",
    "            print(f\"docuument # {count}\")\n",
    "            if newpath != \"RawBCLaws/\":\n",
    "                print(newpath)\n",
    "                client.download_file(bucket_name, obj['Key'], newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to BC Gov VPN for this\n",
    "downloadlawtitles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1596546",
   "metadata": {},
   "source": [
    "We have set the chunk size to 1 as the CharacterTextSplitter takes the manximum length between the chunk_size and separator. Each setences has variable length. We won't know how long the title is until we read it. Since the titles are short, and each laws title starts in a new line, we have set the chunk size to 1 as we hope each title is more than 1 character long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5ca17-fc72-4d42-948a-8d7425c8fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load titles and split into documents for PGVector\n",
    "loader = TextLoader(\"DB/RawBCLaws/all_act_titles.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1, chunk_overlap=0, separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b076d0-7074-423c-a4f8-0afd080957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"bc_law_titles\"\n",
    "\n",
    "# If the database table already exists, delete it\n",
    "db = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    pre_delete_collection=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0521bef-26c2-4263-bf23-e123ef83a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Is there a law on tenancy act?\"\n",
    "print('\\n' + query + '\\n')\n",
    "docs_with_score = db.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b4337f-ccb9-49b9-a6b6-6cf90b1866c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare query to stored law titles\n",
    "store = PGVector(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ") \n",
    "\n",
    "query = \"Laptop is a device.\"\n",
    "print('\\n' + query + '\\n')\n",
    "docs_with_score = store.similarity_search_with_score(query)\n",
    "\n",
    "for doc, score in docs_with_score:\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Score: \", score)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
