{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fe292-247b-40d1-af80-6232a51de406",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install langchain_community\n",
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a7969-03f6-47b6-a7f5-297b0acecb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "import warnings\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.core.display import display, HTML\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dfa94-2526-4fa3-8184-4888b1c5fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEO4J_URI = 'bolt://citz-imb-ai-neo4j-svc:7687'\n",
    "NEO4J_URI = 'bolt://' + os.getenv('NEO4J_HOST') + ':7687'\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USER')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = 'neo4j' #os.getenv('NEO4J_DB')\n",
    "print(NEO4J_URI)\n",
    "print(NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30787237-c08c-4691-b21c-90c4921ee3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf943ba0-bffb-4b49-a257-a3c562745aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (n) \n",
    "  RETURN count(n)\n",
    "  \"\"\"\n",
    "result = kg.query(cypher)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c89ab-93a2-4677-b4de-663ac0db8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68a90d-7bc1-4d1e-bf0e-09eda5a5b7d3",
   "metadata": {},
   "source": [
    "## Please download the glossary file from S3 before running the below code\n",
    "if you have the s3 credentials you can excute these commands in the notebook it self\n",
    "```\n",
    "from utility.s3_glossary import download_data\n",
    "bucket_name = \"IMBAIPilot\"\n",
    "download_data(\"bclaws/glossary\", \"JSON_glossary/\", bucket_name)\n",
    "```\n",
    "\n",
    "You can also manually download this by executing the script in the utility folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41a7b4-fd2b-4f42-b2a8-9a138a9e0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = lambda x: {\"filename\": x}\n",
    "f = open('./utility/JSON_glossary/glossary.json')\n",
    "glossaries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba1321-d600-4466-a157-40ae3c95d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glossaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf450c1-660e-4ac8-b286-9a5d131cd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=20, tokens_per_chunk=256)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e406f-b2c4-4efa-9210-2a0a1182a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:UpdatedChunk {chunkId: $chunkParam.chunkId})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId, \n",
    "        mergedChunk.text = $chunkParam.text,\n",
    "        mergedChunk.type = $chunkParam.type,\n",
    "        mergedChunk.url = $chunkParam.url,\n",
    "        mergedChunk.glossaryTerm = $chunkParam.glossaryTerm\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f87dc-d2d2-43ac-b46d-65cbee4c77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embeddings = \"\"\"\n",
    "        MATCH (chunk:UpdatedChunk) WHERE\n",
    "        chunk.chunkId = $chunkParam.chunkId\n",
    "        AND chunk.chunkSeqId = $chunkParam.chunkSeqId\n",
    "        AND chunk.text = $chunkParam.text\n",
    "        AND chunk.type = $chunkParam.type\n",
    "        AND chunk.url = $chunkParam.url\n",
    "        AND chunk.glossaryTerm = $chunkParam.glossaryTerm\n",
    "        AND chunk.textEmbedding is NULL\n",
    "        CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", $vector)\n",
    "        RETURN chunk\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a7a06-c3d0-45bb-af0e-35f8d32d9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of glossaries in bc gov\n",
    "print(len(glossaries['terms']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb2f9c-5b30-404e-aec9-00d3d0881e64",
   "metadata": {},
   "source": [
    "## This code below will create the chunk and embeddings of the glossary terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de167c-6015-453a-80c1-81e902e07149",
   "metadata": {},
   "outputs": [],
   "source": [
    "for glossary in enumerate(glossaries['terms']):\n",
    "    #print(glossary)\n",
    "    #print(glossary[1]['term'])\n",
    "    #print(glossary[1]['description'])\n",
    "    #print(glossary[1]['related_terms'])\n",
    "    text = glossary[1]['term'] + ': ' + glossary[1]['description']\n",
    "    #print(item_text_chunks)\n",
    "    token_split_texts = []\n",
    "    data_type = 'glossary'\n",
    "    # Validate if all the text fits into the 256 token size to create the embeddings\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "    #print(token_split_texts)\n",
    "    # create meta data\n",
    "    for chunk_seq, token in enumerate(token_split_texts):\n",
    "        chunk = {\n",
    "            'type': data_type,\n",
    "            'text': token,\n",
    "            'chunkSeqId': chunk_seq,\n",
    "            'chunkId': f'{data_type}-{glossary[1][\"term\"]}-seq-{str(chunk_seq)}',\n",
    "            'url': 'https://www.bclaws.gov.bc.ca/glossary.html',\n",
    "            'glossaryTerm': glossary[1]['term']\n",
    "        }\n",
    "        print(chunk)\n",
    "        kg.query(merge_chunk_node_query, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "        vector = embeddings.embed_query(chunk['text'])\n",
    "        result = kg.query(create_embeddings, params={'chunkParam':chunk, 'vector':vector})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91d9d0-1656-4414-922c-5980853f382b",
   "metadata": {},
   "source": [
    "## Now that we have index all the glossary we now need to attach the references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_chunks = \"\"\"\n",
    "      MATCH (chunk:UpdatedChunk), (f:UpdatedChunk)\n",
    "      WHERE\n",
    "        chunk.chunkId = $chunkParam.chunkId\n",
    "        AND chunk.chunkSeqId = $chunkParam.chunkSeqId\n",
    "        AND chunk.text = $chunkParam.text\n",
    "        AND chunk.glossaryTerm = $chunkParam.glossaryTerm1\n",
    "        AND chunk.type = $chunkParam.type\n",
    "        AND f.type = $chunkParam.type\n",
    "        AND f.glossaryTerm = $chunkParam.glossaryTerm2\n",
    "        AND f.chunkId = $chunkParam.chunkId2\n",
    "        AND f.chunkSeqId = 0\n",
    "      MERGE (chunk)-[newRelationship:RELATED_TERMS]->(f)\n",
    "      RETURN count(newRelationship)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da6fe1-e7b2-463c-9a49-3cbbe3b5e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "for glossary in enumerate(glossaries['terms']):\n",
    "    text = glossary[1]['term'] + ': ' + glossary[1]['description']\n",
    "    #print(item_text_chunks)\n",
    "    token_split_texts = []\n",
    "    data_type = 'glossary'\n",
    "    # Validate if all the text fits into the 256 token size to create the embeddings\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "    for chunk_seq, token in enumerate(token_split_texts):\n",
    "        for glossary_terms in glossary[1]['related_terms']:\n",
    "            chunk = {\n",
    "                'type': data_type,\n",
    "                'text': token,\n",
    "                'chunkSeqId': chunk_seq,\n",
    "                'chunkId': f'{data_type}-{glossary[1][\"term\"]}-seq-{str(chunk_seq)}',\n",
    "                'url': 'https://www.bclaws.gov.bc.ca/glossary.html',\n",
    "                'glossaryTerm1': glossary[1]['term'],\n",
    "                'glossaryTerm2': glossary_terms,\n",
    "                'chunkId2': f'{data_type}-{glossary_terms}-seq-0'\n",
    "            }\n",
    "            print(chunk)\n",
    "            ret = kg.query(connect_chunks, \n",
    "            params={\n",
    "                'chunkParam': chunk\n",
    "            })\n",
    "            print(ret)\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92717ee-7c11-47e0-9feb-0f8af65ab471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, glossary in enumerate(glossaries['terms']):\n",
    "    text = glossary['term'] + ': ' + glossary['description']\n",
    "    token_split_texts = []\n",
    "    data_type = 'glossary'\n",
    "    \n",
    "    # Split text into chunks fitting the 256 token size\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "    \n",
    "    for chunk_seq, token in enumerate(token_split_texts):\n",
    "        for glossary_term in glossary['related_terms']:\n",
    "            chunk = {\n",
    "                'type': data_type,\n",
    "                'text': token,\n",
    "                'chunkSeqId': chunk_seq,\n",
    "                'chunkId': f'{data_type}-{glossary[\"term\"]}-seq-{chunk_seq}',\n",
    "                'url': 'https://www.bclaws.gov.bc.ca/glossary.html',\n",
    "                'glossaryTerm1': glossary['term'],\n",
    "                'glossaryTerm2': glossary_term,\n",
    "                'chunkId2': f'{data_type}-{glossary_term}-seq-0'  # Assuming seq-0 for related terms\n",
    "            }\n",
    "            \n",
    "            # Execute the query with the current chunk parameters\n",
    "            ret = kg.query(connect_chunks, params={'chunkParam': chunk})\n",
    "            print(chunk)\n",
    "            print(ret)\n",
    "            print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8afd67-544f-464b-8a7b-f06ee6ffbd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33149836-32d9-49e9-a4bc-a77520ab881f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
