{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e24a3-19f9-4e28-8c85-5496f25539bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf246ab-bbac-4984-a7e2-c23a5936962b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install diffgram\n",
    "!pip install llama_index\n",
    "!pip install matplotlib\n",
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f92142-5c34-4a96-8928-cd85fb8dc209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from diffgram import Project\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "import matplotlib as mpl\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5083615-6b22-4da5-a8ab-ecd31b5b9ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258828ae-43c5-41d3-a43d-0690808d0b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_local = Project(host = \"https://dd4d-2604-3d08-4f7f-e8c0-5844-ee59-358e-598.ngrok-free.app\",\n",
    "        project_string_id = \"valiantbiter\",\n",
    "        client_id = \"LIVE__ywmyayoir4c6zx1kz5j4\",\n",
    "        client_secret = \"wwwh2eiwc7f4q35qywxgghuyfuh2oemwshec0tiu4gctapsxqe3orcyfe5u3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f857a-4abe-40ec-b492-afd73c6fb0fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a directory in diffgram with dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03828a4e-4254-4f4c-abe3-7c30ae780f29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"dataset_from_api_v5\"\n",
    "#project_local.set_directory_by_name(dataset_name)\n",
    "#directory = project_local.directory.new(name = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b7410-1281-478d-a669-f5362f422471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You may need to run this twice to see if the directory is created\n",
    "directory = None\n",
    "try:\n",
    "    directory = project_local.directory.get(name = dataset_name)\n",
    "except:\n",
    "    directory = project_local.directory.new(name=dataset_name)\n",
    "if directory is not None:    \n",
    "    print(directory.__dict__)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c738b-03d1-47a1-b4ad-55d7cad54032",
   "metadata": {},
   "source": [
    "## Import all the files \n",
    "### make sure you have the diffgram_processing_v2 folder which has all the data arranged for NER task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a32b6-2898-4f9e-9000-220dbecea460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef452fa-6ef0-4c60-9363-512f7372b120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_metadata = lambda x: {\"filename\": x}\n",
    "diffgram_documents = SimpleDirectoryReader(\"diffgram_processing_v2\",file_metadata=file_metadata).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66845844-502e-4ff2-9b8f-3afcb7005621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(diffgram_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbc6de-aa67-4206-b7c5-b16ef724c00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(diffgram_documents[0].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e19157-775c-4d00-ba90-9f116eaab96f",
   "metadata": {},
   "source": [
    "## Fetch the files and add it to diffgram\n",
    "if you want to insert one file at a time\n",
    "    file = project_local.file.from_local(\"diffgram_processing_v2/800.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807849a-b066-4484-9227-06344895bd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "minimum = min([len(diffgram_documents), 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad229814-efd2-435c-b661-d7f51829127b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = diffgram_documents[1].metadata['filename']\n",
    "file = project_local.file.from_local(filename,directory_id=directory.__dict__['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5a9004-47ee-4cf3-9227-920799ccf997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for document in range(0, minimum):\n",
    "        filename = diffgram_documents[document].metadata['filename']\n",
    "        file = project_local.file.from_local(filename,directory_id=directory.__dict__['id'])\n",
    "        print(file)\n",
    "        print(file.__dict__)\n",
    "        print(dataset_name)\n",
    "        file_list = []\n",
    "        file_list.append(file.__dict__['id'])\n",
    "        #result = directory.add(file_id_list = file_list)\n",
    "        #print(result)\n",
    "except:\n",
    "    print(\"A file with this filename already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a6f78b-e639-458c-9825-3a6d5100597e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fetch and add the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ca54b-6d63-4678-a675-b974e0864aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('legal_ner_schema.json')\n",
    "NER_schema = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bea780-dd36-4a97-9026-681c49fb3c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Id the Labels\n",
    "# Create label to ID mapping\n",
    "label2id = []\n",
    "id2label = []\n",
    "for id, label in enumerate(NER_schema['schema']):\n",
    "    label2id.append(id)\n",
    "    id2label.append(NER_schema['schema'][id]['name'])\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227ff0f-dd22-4453-bf21-0804827a3766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NER_schema_name = 'NER_TRAINING_SCHEMA'\n",
    "schema_id = None\n",
    "schemas = project_local.schema.list()\n",
    "print(json.dumps(schemas, indent=2))\n",
    "for schema in schemas:\n",
    "    if schema['name'] == NER_schema_name:\n",
    "        schema_id = schema['id']\n",
    "if schema_id == None:\n",
    "    json_response = project_local.new_schema(name=NER_schema_name)\n",
    "    schema_id = json_response[\"id\"]\n",
    "    for NER in NER_schema['schema']:\n",
    "        print(NER['name'])\n",
    "        project_local.label_new(NER, schema_id=schema_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a67322-c4e9-4472-9323-68df2c8d5f5e",
   "metadata": {},
   "source": [
    "## Create a Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd9623-9587-465e-8b31-bfb42a95116d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "member_list = project_local.get_member_list()\n",
    "member_list_ids = [x['member_id'] for x in member_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed3512-666d-4a22-afc7-7b17b0bca242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schemas = project_local.schema.list()\n",
    "print(json.dumps(schemas, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcfec6-61e9-44da-bb26-dd82bdcf7c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "JOB_NAME = \"Law_NER_task1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c995ee9-c929-496b-a608-68392e2b6b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = project_local.job.new(\n",
    "    name = JOB_NAME,\n",
    "    instance_type = \"box\",\n",
    "    share = \"Project\",\n",
    "    sync_directories = [directory],\n",
    "    label_schema_id = schema_id,\n",
    "    tag_list = [\"Laws\", \"Acts\", \"Regulations\"],\n",
    "    members_list_ids = member_list_ids,\n",
    "    auto_launch = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bff895c-c09a-4996-a45b-58c109d83e8e",
   "metadata": {},
   "source": [
    "## Export annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0edbd7-29bd-416d-b4ef-54186c10d4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Get the job based on the id and name\n",
    "def get_completed_job():\n",
    "    get_job = project_local.job.list()\n",
    "    for jobs_completed in get_job:\n",
    "        if (jobs_completed['status'] == 'complete') and (jobs_completed['name'] == JOB_NAME):\n",
    "            return jobs_completed\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750adc45-9f3f-4da3-a0c2-e9300b5b8c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_job = get_completed_job()\n",
    "if completed_job is not None:\n",
    "    print(f\"The status of the job {completed_job['name']} (id = {completed_job['id']})  is {completed_job['status']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e4847-5ff0-4a67-95eb-1599b38a80ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = project_local.job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d1ae0-689e-422f-83e8-118cd6673343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.refresh_from_dict(completed_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc384e-9d7a-4a80-8cd9-dcc62cc8bcd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_annotations = results.generate_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f521f-9628-4317-8976-f2ade0fe6f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIFFGRAM_EXPORT_ADDITIONAL_PARAMETERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541d21c-fc58-4e89-8287-e18ea7a118fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\" Number of annotated data {len(completed_annotations) - DIFFGRAM_EXPORT_ADDITIONAL_PARAMETERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c2144-88d7-41ec-ab24-74735a143d6e",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "### processing the annotated data to train the A.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc84d22-f2bf-40b8-a49e-c6af3f34b7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "sentences = []\n",
    "labels = []\n",
    "data_index = 0\n",
    "for completed_annotation in completed_annotations:\n",
    "    #print(f\"{completed_annotation} ----\")\n",
    "    if (completed_annotation != 'attribute_groups_reference')  \\\n",
    "        and (completed_annotation != 'export_info') \\\n",
    "        and (completed_annotation != 'label_map') \\\n",
    "        and (completed_annotation != 'readme') \\\n",
    "        and (completed_annotation != 'label_colour_map'):\n",
    "        sentence_local = []\n",
    "        labels_local = []\n",
    "        # First get the point where the annotation is started\n",
    "        for start in completed_annotations[completed_annotation]['instance_list']:\n",
    "            if 'start_token' in start:\n",
    "                start_token =  start['start_token']\n",
    "                break\n",
    "            \n",
    "        #start_token = completed_annotations[completed_annotation]['instance_list'][0]['start_token']\n",
    "        for annotated_index in range(start_token, len(completed_annotations[completed_annotation]['text']['tokens']['words'])):\n",
    "            # check if this text is annotated\n",
    "            for data in completed_annotations[completed_annotation]['instance_list']:\n",
    "                if 'start_token' in data:\n",
    "                    if annotated_index == data['start_token']:\n",
    "                        sentence_local.append(completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value'])\n",
    "                        labels_local.append(completed_annotations['label_map'][str(data['label_file_id'])])\n",
    "                        #print(f\"{completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value']} - {completed_annotations['label_map'][str(data['label_file_id'])]}\")\n",
    "                        break;\n",
    "        sentences.append(sentence_local)       \n",
    "        labels.append(labels_local)\n",
    "        data_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f1475-2bd0-496f-bf82-1b4e68e722f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e6c63-4e64-47e9-aaf2-c4e123ed67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "# Creating a pandas DataFrame\n",
    "for iter in range (0, len(sentences)):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    ner_df = pd.DataFrame({\n",
    "        \"Token\": sentences[iter],\n",
    "        \"Label\": labels[iter]\n",
    "    })  \n",
    "    # Display the DataFrame with some custom styles\n",
    "    ner_df.style.set_properties(**{'background-color': 'lightyellow', \n",
    "                               'color': 'black',\n",
    "                               'border-color': 'black'})\n",
    "    # Use tabulate to display a nice table in the terminal\n",
    "    print(tabulate(ner_df, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad661e-5c57-4986-9ae6-df76ea8b5240",
   "metadata": {},
   "source": [
    "## Preparing the data for input to pytorch\n",
    "### We need to make all the data the same length by padding if they are not 255 tokens in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162077bf-133d-4aa1-b6be-c2cfa625bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7e125-5c85-4c51-b9be-6877382cd1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 255\n",
    "PAD_TOKEN = \"[PAD]\"\n",
    "PAD_LABEL = \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d2a6b-10b9-48df-986c-5afe3abb9d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequence, max_length, pad_value):\n",
    "    return sequence + [pad_value] * (max_length - len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b6fd5-fe1b-485a-adbe-990ddfcedd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "data = []\n",
    "NER_label = []\n",
    "for sent_id, (sentence, sent_labels) in enumerate(zip(sentences, labels)):\n",
    "    tmp_data = []\n",
    "    tokens = sentence  # Simple tokenization\n",
    "    #print(tokens)\n",
    "    sentence_string = \"\"\n",
    "    for string_value in tokens:\n",
    "        sentence_string += string_value + ' '\n",
    "    #print(sentence_string)\n",
    "    padded_tokens = pad_sequence(tokens, MAX_LENGTH, PAD_TOKEN)\n",
    "    padded_labels = pad_sequence(sent_labels, MAX_LENGTH, PAD_LABEL)\n",
    "    encoded = tokenizer(sentence_string,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        max_length=MAX_LENGTH,  # Adjust based on your needs\n",
    "                        return_tensors='pt')\n",
    "    #print(encoded['input_ids'][0][0])\n",
    "    data.append(encoded)\n",
    "    NER_label.append(padded_labels)\n",
    "    for token_id in range(MAX_LENGTH):\n",
    "        tmp_data.append({\n",
    "            'Sentence_ID': sent_id,\n",
    "            'Token_ID': token_id,\n",
    "            'Token': padded_tokens[token_id],\n",
    "            'NER_Label': padded_labels[token_id],\n",
    "            'Is_Pad': padded_tokens[token_id] == PAD_TOKEN\n",
    "        })\n",
    "    #data.append(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dae967-9041-4869-b884-a43f60eb5dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_label_to_id(ner_label,id2label):\n",
    "    label_id = []\n",
    "    for label in ner_label:\n",
    "        label_id.append(id2label.index(label))\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436139d-91fd-4289-905f-3228f46f5c9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595d8422-aaed-4c63-8e26-dc68d37a0de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "\n",
    "# Training loop (simplified)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef2b5a-d8bc-4729-8c44-a4d149888269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1d11c-ef69-42f2-b674-4012de25eaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(3):  # Number of epochs\n",
    "    for i, batch in enumerate(data):\n",
    "        labelled_id = convert_label_to_id(NER_label[i], id2label)\n",
    "        print(labelled_id)\n",
    "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "        labels = torch.tensor(labelled_id, dtype=torch.long).to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a0586-53e7-494c-a8c7-07549a88e2da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dccd9-9464-4859-abf0-8bd3815e18c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2731d4-5955-42a4-a6b7-af3ab9c8a1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = data\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_data):\n",
    "        # Convert inputs to tensors\n",
    "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        print(predictions)\n",
    "        \n",
    "        # Compare predictions with true labels if available\n",
    "        #true_labels = batch['labels']  # Assuming test data has true labels\n",
    "        # Calculate accuracy or other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2bd08-1464-4162-9784-05dced6f438e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a635f44-ea38-4ec3-ae51-2a818952d502",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ------------------------------------------------------------------------------------------------\n",
    "# **************************************  End of Script  *****************************************\n",
    "# ------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
