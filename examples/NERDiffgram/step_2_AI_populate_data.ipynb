{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519a5b8-6dc3-4277-8c91-d725604a0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3\n",
    "!pip install torch transformers diffgram neo4j anthropic pandas tqdm\n",
    "!pip install llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5ac541-5a2f-4a45-a266-9f4954f28714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from diffgram import Project\n",
    "from typing import List, Dict, Optional\n",
    "import anthropic\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f6eab4-0661-4ede-adc3-58fb0d579ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os.getcwd() since __file__ is not available in interactive environments\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# If your structure is such that the package is in the parent directory, compute the parent directory:\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c7996d-cdd6-4d20-ab07-ef537ecf9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AgenticWorkflow.bedrock_session import get_boto_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9720aa06-77df-4234-ad5b-b6aae2cc154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_boto_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9efc16a-7e28-42e8-bd00-d3906c1657b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime = session.client(\"bedrock-runtime\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a5036b-4530-40b2-aa91-bff59cc5cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claudia_kwargs(prompt):\n",
    "    kwargs = {\n",
    "      \"modelId\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "      \"contentType\": \"application/json\",\n",
    "      \"accept\": \"application/json\",\n",
    "      \"body\": json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 10000,\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "              {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt\n",
    "              }\n",
    "            ]\n",
    "          }\n",
    "        ]\n",
    "      })\n",
    "    }\n",
    "    return kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0701ed-16a4-4cc3-b71a-31ae142157d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Does this work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40eba4e6-83c2-4b2e-8f57-81d9642042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = get_claudia_kwargs(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53479f1a-6e3d-465c-bb59-c1411e83c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    kwargs = get_claudia_kwargs(prompt)\n",
    "    response = bedrock_runtime.invoke_model(**kwargs)\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c26526a-051a-4884-88ec-b973af4515d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab54537f-dade-4ba1-b827-abf04f491019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize, but I don\\'t have any context about what you\\'re referring to when you ask \"Does this work?\" Without more information, I can\\'t determine if something works or not. If you have a specific question, problem, or task in mind, please provide more details so I can better assist you. What exactly are you trying to do or asking about?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e146627f-f1fc-4d65-badb-93287e074c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DIFFGRAM_CONFIG = {\n",
    "    \"host\": \"http://dispatcher:8085\",\n",
    "    \"project_string_id\": \"translucenttracker\",\n",
    "    \"client_id\": \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "    \"client_secret\": \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf0a96a3-5083-461b-94e3-72c295c6bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Project(host=DIFFGRAM_CONFIG[\"host\"],\n",
    "        project_string_id = \"translucenttracker\",\n",
    "        client_id = \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "        client_secret = \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "      )\n",
    "project_local = project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e96e5b7-43d6-46f8-9178-d0ad395eab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 256\n",
    "NUM_TRAIN_SAMPLES = 5440  # Number of samples to use for training\n",
    "NUM_TRAINING_DATA = 5440\n",
    "train_dataset_suffix = \"NER_train_batch_\"\n",
    "test_dataset_suffix = \"NER_test_batch_\"\n",
    "JOB_NAME = \"Law_NER_task1\"\n",
    "JOB_TRAIN_SUFFIX = \"NER_train_JOB_\"\n",
    "JOB_TEST_SUFFIX = \"NER_test_JOB_\"\n",
    "MAX_NUM_OF_TASK = 250\n",
    "NER_schema_name = 'ENTITY_TRAINING_SCHEMA'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a7eb45-358c-46b8-845d-8b24f52d323c",
   "metadata": {},
   "source": [
    "## Import all the files \n",
    "### make sure you have the diffgram_processing_v2 folder which has all the data arranged for NER task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92689df2-b043-406a-b07a-6abe61e86a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb5f37c-1ab5-4142-8607-8185cdf97d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = lambda x: {\"filename\": x}\n",
    "diffgram_documents = SimpleDirectoryReader(\"diffgram_processing\",file_metadata=file_metadata).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725190dc-bd0d-405b-82d2-503b00442a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81611\n"
     ]
    }
   ],
   "source": [
    "print(len(diffgram_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf0fdd85-ed40-4d26-a753-dbfcb2eb290d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk ID: Provincial Sales Tax Act-chunk-Tax if tangible personal property no longer for temporary use-0000\n",
      "Act ID: Provincial Sales Tax Act\n",
      "Regulation ID: None\n",
      "Section Name: Tax if tangible personal property no longer for temporary use\n",
      "Section ID: 51.1\n",
      "Sequence ID: 0\n",
      "Text:\n",
      "1 this section applies to a person in relation to tangible personal property if a section 51 applied to the person in relation to the tangible personal property, and b within 3 years after the date on which the tangible personal property is first used in british columbia and during a calculation year in respect of which tax was payable under section 51, the person uses that property, or allows that property to be used, in british columbia for a purpose other than for temporary use. 2 a person to whom this section applies must pay to the government tax in an amount equal to the amount of tax under section 49 that would have otherwise been payable if that section had applied to the person in relation to the tangible personal property less the amount of tax paid by the person under section 51 in respect of the tangible personal property.\n"
     ]
    }
   ],
   "source": [
    "print(diffgram_documents[500].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890247fc-effd-40d9-90c6-0fea4c191039",
   "metadata": {},
   "source": [
    "## Diffgram utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb6cb0f-4884-468a-b073-73fc66d59726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_directory_exist(dir_name):\n",
    "    project = project_local.directory.get_directory_list(limit=50000)\n",
    "    for project_dir in project:\n",
    "        if (project_dir.__dict__['nickname'] == dir_name):\n",
    "            return project_dir\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad38eae0-8cac-4d0b-9b2b-f295d05121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You may need to run this twice to see if the directory is created\n",
    "def create_diffgram_directory(dataset_name):\n",
    "    #directory = project_local.directory.get(name = dataset_name)\n",
    "    directory = check_if_directory_exist(dataset_name)\n",
    "    if (directory is None):\n",
    "        project_local.directory.new(name=dataset_name)\n",
    "        directory = check_if_directory_exist(dataset_name)\n",
    "        print(directory.__dict__)    \n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd73b019-c012-4035-8275-65cbde52afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check if file exist in the dir\n",
    "def check_if_file_exist_in_dir(filename):\n",
    "    file = project_local.file.file_list_exists(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "734f5146-e911-4af4-bb3e-ce83b348f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_job(data_suffix, job_suffix, index, member_list_ids):\n",
    "    dataset_batch_name = data_suffix + str(index)\n",
    "    directory = create_diffgram_directory(dataset_batch_name)\n",
    "\n",
    "    if directory is None:\n",
    "        print(f\"{dataset_batch_name} Directory does not exist\")\n",
    "        return\n",
    "\n",
    "    job_name = job_suffix + str(index)\n",
    "\n",
    "    job = project_local.job.new(\n",
    "        name = job_name,\n",
    "        instance_type = \"box\",\n",
    "        share = \"Project\",\n",
    "        sync_directories = [directory],\n",
    "        label_schema_id = schema_id,\n",
    "        tag_list = [\"Laws\", \"Acts\", \"Regulations\"],\n",
    "        members_list_ids = member_list_ids,\n",
    "        auto_launch = True\n",
    "    )\n",
    "    print(f\"The {job_name} task is created\")\n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5991441f-4cc6-4b29-a6f0-17127bfa347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_dataset(index,batch_size, offset, directory):\n",
    "    for document in range((index+offset) * batch_size, ((index + offset) * batch_size) + batch_size):\n",
    "        filename = diffgram_documents[document].metadata['filename']\n",
    "        # check if the file exist in the diffgram directory\n",
    "        try:\n",
    "            file = project_local.file.from_local(filename,directory_id=directory.__dict__['id'])\n",
    "        except:\n",
    "            print(f\"File with {filename} exist in this directory. Continuing ....\")\n",
    "            continue;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb3578-211d-43e6-8a7e-fe72c5696baa",
   "metadata": {},
   "source": [
    "## get schmea id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b66919-7417-4f73-bb63-09049594019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Schemas in Diffgram:\n",
      "[\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 8,\n",
      "    \"is_default\": true,\n",
      "    \"member_created_id\": 1,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"Default Schema\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-04 22:16:17\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 9,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"NER_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:08:24\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 11,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"ENTITY_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:20:02\",\n",
      "    \"time_updated\": null\n",
      "  }\n",
      "]\n",
      "Schema 'ENTITY_TRAINING_SCHEMA' already exists with id: 11\n"
     ]
    }
   ],
   "source": [
    "schema_id = None\n",
    "\n",
    "# List the existing schemas in your Diffgram project.\n",
    "schemas = project.schema.list()\n",
    "print(\"Existing Schemas in Diffgram:\")\n",
    "print(json.dumps(schemas, indent=2))\n",
    "\n",
    "# Check if a schema with the name NER_schema_name already exists.\n",
    "for schema in schemas:\n",
    "    if schema.get('name') == NER_schema_name:\n",
    "        schema_id = schema.get('id')\n",
    "        break\n",
    "\n",
    "# If the schema does not exist, create a new one.\n",
    "if schema_id is None:\n",
    "    print(f\"Schema '{NER_schema_name}' not found. Creating a new one...\")\n",
    "    json_response = project.new_schema(name=NER_schema_name)\n",
    "    schema_id = json_response.get(\"id\")\n",
    "    print(f\"Created new schema with id: {schema_id}\")\n",
    "else:\n",
    "    print(f\"Schema '{NER_schema_name}' already exists with id: {schema_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c1ec0-3d8d-4c3a-b0ea-4bf7ed131e53",
   "metadata": {},
   "source": [
    "## Uplaod the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b82b43cd-5919-4139-a9b1-cd9eb1a78fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def create_datasets(diffgram_documents, num_training_data, batch_size, train_suffix, test_suffix, job_train_suffix, job_test_suffix):\n",
    "    #check if the lenght of all the data is equal to or more than num_training_data\n",
    "    if (len(diffgram_documents) < num_training_data):\n",
    "        print(f\"Not sufficient data for training {len(diffgram_documents)}\")\n",
    "        return\n",
    "    \n",
    "    train_batch_size = math.floor(num_training_data/batch_size)\n",
    "    test_batch_size = math.floor((num_training_data * (5 /100))/ batch_size)\n",
    "    #train_dataset_name = \"NER_train_batch_\"\n",
    "    \n",
    "    print(f\"The batch size of the training data is : {train_batch_size}\")\n",
    "    print(f\"The batch size of the test data is: {test_batch_size}\")\n",
    "    \n",
    "    member_list = project.get_member_list()\n",
    "    member_list_ids = [x['member_id'] for x in member_list]\n",
    "    \n",
    "    #schemas = project_local.schema.list()\n",
    "    train_batch_size = max(MAX_NUM_OF_TASK, train_batch_size)\n",
    "    test_batch_size = max(MAX_NUM_OF_TASK, test_batch_size)\n",
    "    \n",
    "    for index in range(66, train_batch_size):\n",
    "        directory = create_dataset_job(train_suffix, job_train_suffix, index, member_list_ids)\n",
    "        \n",
    "        print(f\"Creating / Uploading data to directory {directory.__dict__['nickname']}\")\n",
    "        upload_files_to_dataset(index,batch_size, 0, directory)\n",
    "        \n",
    "#    for index in range(0, test_batch_size):\n",
    "#        directory = create_dataset_job(test_suffix, job_test_suffix, index, member_list_ids)\n",
    "#        \n",
    "#        print(f\"Creating / Uploading data to directory {directory.__dict__['nickname']}\")\n",
    "#        upload_files_to_dataset(index,batch_size, train_batch_size+1, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb5019-682a-45e2-937a-0eddad15ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets(diffgram_documents[2112:], NUM_TRAINING_DATA, BATCH_SIZE, train_dataset_suffix, test_dataset_suffix,  JOB_TRAIN_SUFFIX, JOB_TEST_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0601d03-0651-4edf-837b-d1756037f5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
