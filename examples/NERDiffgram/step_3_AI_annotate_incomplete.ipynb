{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f44ffe-c6d7-451d-ac93-e91fe2330336",
   "metadata": {},
   "source": [
    "# Annotate incomplete or partially annotated files\n",
    "\n",
    "IF there are chunks that are not commpletely annotated or have partial annotation run this script as it may try to re-annoate only the parts of the chunk that are not completely annotated. This may require manual cleanup using diffgram and then use this script to see if the A.I can continue to annotate. \n",
    "\n",
    "There is no gurantee the A.I will be succesful to annotate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0196023-cfd0-4171-9859-9662d3b93fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers diffgram neo4j anthropic pandas tqdm\n",
    "!pip install llama_index\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a9b4b-390a-489d-9f31-b37f9ecf236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix-otel\n",
    "!pip install openinference-instrumentation-bedrock opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d548875c-6194-47f4-b56e-8eff4a06ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from diffgram import Project\n",
    "from typing import List, Dict, Optional\n",
    "import anthropic\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef6f63-c21d-45e8-b3df-d4315b1d27f3",
   "metadata": {},
   "source": [
    "## Connect to Arize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c809b0d-a79d-46c1-8f4f-f92ce5166b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the new tracking code\n",
    "#from bedrock_output_fix import setup_claude_tracking, get_response_with_tracking\n",
    "from opentelemetry.trace import get_tracer_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac42c16-c616-44f8-9ec6-a8f5b5a7d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "  project_name=\"pre-annotation-with-AI\", # Default is 'default'\n",
    "  endpoint=\"http://phoenix:6006/v1/traces\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12867e19-fdca-4be8-ae45-dde3d4d464e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.bedrock import BedrockInstrumentor\n",
    "BedrockInstrumentor().instrument(tracer_provider=tracer_provider,\n",
    "                                capture_response_body=True  # Enable response capture\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28faac44-39d0-4dd9-95db-fc673511b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use os.getcwd() since __file__ is not available in interactive environments\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# If your structure is such that the package is in the parent directory, compute the parent directory:\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "\n",
    "# Add the parent directory to sys.path if it's not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec51d5-e167-47d7-8577-1d6adb3a3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AgenticWorkflow.bedrock_session import get_boto_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5085722-b0a8-46a0-bd8f-fbfb4176e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_boto_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b376238-7027-4fc2-9935-9bb942b5a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  get_claude_kwargs\n",
    "from get_claude_kwargs import get_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bcf6e-958d-4d1b-b7a5-13b97f55c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_with_tracking(prompt, job_data = None):\n",
    "    with get_tracer_provider().get_tracer(__name__).start_as_current_span(\"claude_request\") as span:\n",
    "        # Convert nested structure to flat attributes with dot notation\n",
    "        #span.set_attribute(\"llm.model_name\", \"anthropic.claude-3-5-sonnet-20240620-v1:0\")\n",
    "        #span.set_attribute(\"llm.token_count.prompt\", len(prompt.split()))\n",
    "        #span.set_attribute(\"llm.invocation_parameters\", get_response(prompt))\n",
    "        \n",
    "        try:\n",
    "            span.set_attribute(\"input.value\", prompt)\n",
    "            # Get response using original function\n",
    "            output = get_response(prompt)\n",
    "                     \n",
    "            # Set output as string\n",
    "            span.set_attribute(\"output.value\", output if output else \"None\")\n",
    "        \n",
    "            span.set_attribute(\"task.name\", job_data['nickname'] if job_data else \"None\")\n",
    "            span.set_attribute(\"task.index\", job_data['index'] if job_data else \"None\")\n",
    "            span.set_attribute(\"task.fileID\", job_data['file'] if job_data else \"None\")\n",
    "            \n",
    "            # Set span kind as string\n",
    "            span.set_attribute(\"openinference.span.kind\", \"LLM\")\n",
    "            \n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Log error as flat strings\n",
    "            span.set_attribute(\"error.message\", str(e))\n",
    "            span.set_attribute(\"error.type\", e.__class__.__name__)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395baff-7ae5-47af-b3ae-fed7ddf5583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"test if the bedrock connection is established\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c3ed3-8fbe-4196-a815-3be9f167462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response_with_tracking(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2c76b-11f8-4aaf-b30f-cf42859e3218",
   "metadata": {},
   "source": [
    "## Connect to Diffgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696e367a-c418-4853-924d-9dfa078c8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffgram project configuration\n",
    "DIFFGRAM_CONFIG = {\n",
    "    \"host\": \"http://dispatcher:8085\",\n",
    "    \"project_string_id\": \"translucenttracker\",\n",
    "    \"client_id\": \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "    \"client_secret\": \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e40d088-88b6-40cb-ab03-47affd29a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to Diffgram project\n",
    "project = Project(host=DIFFGRAM_CONFIG[\"host\"],\n",
    "        project_string_id = \"translucenttracker\",\n",
    "        client_id = \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "        client_secret = \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "      )\n",
    "project_local = project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04a648-75df-46cd-94e1-201e4b0abd99",
   "metadata": {},
   "source": [
    "## Fetch Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd4c980-b929-47af-9f20-f103eebe589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and manage NER schema in Diffgram\n",
    "# Retrieve and process existing schema labels\n",
    "NER_schema_name = 'ENTITY_TRAINING_SCHEMA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703da465-1db1-47e0-bc97-8bce8b3ef7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_list(id):\n",
    "    auth = project.session.auth\n",
    "    url = f\"{DIFFGRAM_CONFIG['host']}/api/project/{DIFFGRAM_CONFIG['project_string_id']}/labels?schema_id={id}\"\n",
    "    # Step 4: Make the POST request using the SDK's session auth\n",
    "    response = requests.get(url, auth=auth)\n",
    "    # Step 5: Handle the response\n",
    "    if response.status_code == 200:\n",
    "        #print(\"Annotation update successful!\")\n",
    "        #pprint.pprint(response.json())  # View the updated data\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)  # Print error details for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b282ab2-1ac5-405b-b4d0-bf4b6a46ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Schemas in Diffgram:\n",
      "[\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 8,\n",
      "    \"is_default\": true,\n",
      "    \"member_created_id\": 1,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"Default Schema\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-04 22:16:17\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 9,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"NER_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:08:24\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 11,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"ENTITY_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:20:02\",\n",
      "    \"time_updated\": null\n",
      "  }\n",
      "]\n",
      "Schema 'ENTITY_TRAINING_SCHEMA' already exists with id: 11\n",
      "{'O', 'I-SECTION_ID', 'I-DEFINITION', 'B-SEQUENCE_ID', 'I-AUTHORITY', 'I-REQUIREMENT', 'B-METADATA_VALUE', 'I-REGULATION_ID', 'B-SUBSECTION_REF', 'B-METADATA_FIELD', 'B-SECTION_NAME', 'I-SECTION_NAME', 'B-REGULATION_ID', 'B-DEFINITION', 'I-SEQUENCE_ID', 'B-AUTHORITY', 'I-SUBSECTION_REF', 'I-METADATA_FIELD', 'B-SECTION_ID', 'B-ACT_ID', 'I-SECTION_REF', 'I-METADATA_VALUE', 'B-REQUIREMENT', 'B-SECTION_REF', 'I-ACT_NAME', 'B-CHUNK_ID', 'B-ACT_NAME', 'I-ACT_ID', 'I-CHUNK_ID'}\n"
     ]
    }
   ],
   "source": [
    "schema_id = None\n",
    "\n",
    "# List the existing schemas in your Diffgram project.\n",
    "schemas = project.schema.list()\n",
    "schema_list = schemas\n",
    "print(\"Existing Schemas in Diffgram:\")\n",
    "print(json.dumps(schemas, indent=2))\n",
    "\n",
    "# Check if a schema with the name NER_schema_name already exists.\n",
    "for schema in schemas:\n",
    "    if schema.get('name') == NER_schema_name:\n",
    "        schema_id = schema.get('id')\n",
    "        break\n",
    "\n",
    "# If the schema does not exist, create a new one.\n",
    "if schema_id is None:\n",
    "    print(f\"Schema '{NER_schema_name}' not found. Creating a new one...\")\n",
    "    json_response = project.new_schema(name=NER_schema_name)\n",
    "    schema_id = json_response.get(\"id\")\n",
    "    print(f\"Created new schema with id: {schema_id}\")\n",
    "else:\n",
    "    print(f\"Schema '{NER_schema_name}' already exists with id: {schema_id}\")\n",
    "\n",
    "schema_labels = get_schema_list(schema_id)\n",
    "\n",
    "# Retrieve existing labels for the schema to avoid duplicates.\n",
    "schema_label_id_value = []\n",
    "if schema_labels is not None:\n",
    "    labels = schema_labels['labels_out']\n",
    "    for label in labels:\n",
    "        value = {}\n",
    "        value['id'] = label['id']\n",
    "        value['name'] = label['label']['name']\n",
    "        schema_label_id_value.append(value)\n",
    "\n",
    "existing_label_names = set()\n",
    "try:\n",
    "    schema_label_id_value[0]['name']\n",
    "    for label in schema_label_id_value:\n",
    "            label_name = label.get(\"name\")\n",
    "            if label_name:\n",
    "                existing_label_names.add(label_name)\n",
    "    print(existing_label_names)      \n",
    "except:\n",
    "     print(\"There are no schema labels\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e7a535-4274-46a8-a2fc-10fec23a24cf",
   "metadata": {},
   "source": [
    "## Diffgram Send Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59e1e639-4b55-4dc7-b936-68439192b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to send pre-annotations back to Diffgram\n",
    "# Handle API communication and response processing\n",
    "def send_preannotation_to_diffgram(file):\n",
    "    # Step 1: Extract the session's auth credentials (client_id and client_secret)\n",
    "    auth = project_local.session.auth\n",
    "\n",
    "    # Step 2: Define the API URL for the custom annotation update endpoint\n",
    "    file_id = file.id  # Replace with your file ID\n",
    "    #project_string_id = \"your_project_string_id\"  # Replace with your project string ID\n",
    "    url = f\"{DIFFGRAM_CONFIG['host']}/api/project/{DIFFGRAM_CONFIG['project_string_id']}/file/{file_id}/annotation/update\"\n",
    "\n",
    "    # Step 3: Define the data (e.g., instance_list) for updating annotations\n",
    "    data = {\n",
    "        \"instance_list\": file.__dict__['instance_list']\n",
    "    }\n",
    "\n",
    "    # Step 4: Make the POST request using the SDK's session auth\n",
    "    response = requests.post(url, json=data, auth=auth)\n",
    "\n",
    "    # Step 5: Handle the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Annotation update successful!\")\n",
    "        # print(response.json())  # View the updated data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)  # Print error details for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ed05b4-6b3c-468a-a382-1050d79d53ed",
   "metadata": {},
   "source": [
    "## NER Validation Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81a6af6d-7feb-4e15-bf7d-3fc2b3f870fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured prompt for NER tagging\n",
    "# Include rules and formatting guidelines for entity recognition\n",
    "def create_ner_prompt(text: str, schema: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Creates a prompt for NER tagging that defaults to O tag for most text.\n",
    "    \"\"\"\n",
    "    schema_tags = sorted(set(s['name'] for s in schema))\n",
    "    \n",
    "    prompt = \"\"\"You are a Named Entity Recognition system for legislative text.\n",
    "Your task is to label each word using only the following allowed tags:\n",
    "{allowed_tags}\n",
    "\n",
    "Rules:\n",
    "1. Default to 'O' tag - most words should be tagged as Outside\n",
    "2. Only tag these specific elements:\n",
    "   - Section references (e.g., \"section 46\" -> B-SECTION_REF, I-SECTION_REF)\n",
    "   - Subsection references (e.g., \"(2)\", \"(a)\" -> B-SUBSECTION_REF)\n",
    "   - Essential metadata fields and their values\n",
    "3. Tag principles:\n",
    "   - All punctuation should be 'O'\n",
    "   - Use B- prefix only for start of key references\n",
    "   - Use I- prefix for continuing words of same reference\n",
    "   - When in doubt, use 'O' tag\n",
    "\n",
    "Each space should be annotated separately. For e.g. If you see child 's annotate it as child and 's as two different words as there is a sapce between them. All ' s must be treated as one word 's.\n",
    "If there are no spaces between words like Act-Motor or 2subsection or 1in or b or ill. . treat this as one word. If b. and c. are separatd by a space then b. is one word and c. is another word. If there is a space between say en . then en is one word and the . is another word which should have its own label.\n",
    "\n",
    "Output format:\n",
    "[\n",
    "    {{\"word\": \"section\", \"tag\": \"B-SECTION_REF\"}},\n",
    "    {{\"word\": \"46\", \"tag\": \"I-SECTION_REF\"}},\n",
    "    {{\"word\": \",\", \"tag\": \"O\"}},\n",
    "    {{\"word\": \"subsection\", \"tag\": \"O\"}},\n",
    "    {{\"word\": \"(\", \"tag\": \"O\"}},\n",
    "    {{\"word\": \"2\", \"tag\": \"B-SUBSECTION_REF\"}},\n",
    "    {{\"word\": \"'s\", \"tag\": \"O\"}},\n",
    "    {{\"word\": \")\", \"tag\": \"O\"}}\n",
    "]\n",
    "\n",
    "Text to label:\n",
    "{text}\n",
    "\n",
    "Provide only the JSON output with no additional explanation.\"\"\"\n",
    "\n",
    "    tags_str = \"\\n\".join(f\"- {tag}\" for tag in schema_tags)\n",
    "    return prompt.format(allowed_tags=tags_str, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37954ff3-0fb5-4a44-b5be-296ffe4fcfda",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda1e4ad-3e90-4462-bffc-8a3b799174bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_data(url):\n",
    "    # Original URL with localhost\n",
    "    # Replace localhost with ngrok URL (example: \"https://example.ngrok.io\")\n",
    "    file_url = url.replace(\"http://localhost:8085\", DIFFGRAM_CONFIG['host'])\n",
    "\n",
    "    # Make the GET request to fetch the file\n",
    "    response = requests.get(file_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON content into a Python dictionary\n",
    "        data = response.json()  # Assuming the file is in JSON format\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da19bc19-1486-4345-875b-8a1d3dafb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for processing Diffgram annotations\n",
    "# Extract and format word-level data from files\n",
    "def get_file_number(completed_annotations, files_index_in_job):\n",
    "    data = []\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    data_index = 0\n",
    "    for completed_annotation in completed_annotations:\n",
    "        try:\n",
    "            file_index = int(completed_annotation)\n",
    "            files_index_in_job.append(completed_annotation)\n",
    "            #print(completed_annotation)\n",
    "            continue\n",
    "        except:\n",
    "            #print(f\"{completed_annotation} is not a file\")\n",
    "            continue\n",
    "            \n",
    "        #print(f\"{completed_annotation} ----\")\n",
    "        if (completed_annotation != 'attribute_groups_reference')  \\\n",
    "            and (completed_annotation != 'export_info') \\\n",
    "            and (completed_annotation != 'label_map') \\\n",
    "            and (completed_annotation != 'readme') \\\n",
    "            and (completed_annotation != 'label_colour_map'):\n",
    "            sentence_local = []\n",
    "            labels_local = []\n",
    "\n",
    "            # First get the point where the annotation is started\n",
    "            for start in completed_annotations[completed_annotation]['instance_list']:\n",
    "                if 'start_token' in start:\n",
    "                    start_token =  start['start_token']\n",
    "                    break\n",
    "\n",
    "            #start_token = completed_annotations[completed_annotation]['instance_list'][0]['start_token']\n",
    "            for annotated_index in range(start_token, len(completed_annotations[completed_annotation]['text']['tokens']['words'])):\n",
    "                # check if this text is annotated\n",
    "                for data in completed_annotations[completed_annotation]['instance_list']:\n",
    "                    if 'start_token' in data:\n",
    "                        if annotated_index == data['start_token']:\n",
    "                            sentence_local.append(completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value'])\n",
    "                            labels_local.append(completed_annotations['label_map'][str(data['label_file_id'])])\n",
    "                            #print(f\"{completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value']} - {completed_annotations['label_map'][str(data['label_file_id'])]}\")\n",
    "                            break;\n",
    "            sentences.append(sentence_local)       \n",
    "            labels.append(labels_local)\n",
    "            data_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19441df6-cc3e-4acf-a9dd-3429b3669d74",
   "metadata": {},
   "source": [
    "## Capture incomplete annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57b0777-c79b-4ae4-8f85-1ba63d9bc953",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = project_local.job\n",
    "get_job = project_local.job.list(limit=10000, page_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479091e8-f1c2-489d-bb76-ba02dd6f0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_data_index = []\n",
    "for job_key, job_list in enumerate(get_job):\n",
    "    try:\n",
    "        nickname = job_list['attached_directories_dict']['attached_directories_list'][0]['nickname']\n",
    "        if nickname:\n",
    "            job_value = {}\n",
    "            job_value['nickname'] = nickname\n",
    "            job_value['index'] = job_key\n",
    "            jobs_with_data_index.append(job_value)\n",
    "        #print(nickname)\n",
    "    except KeyError:\n",
    "        print(\"Key not found.\")\n",
    "    except IndexError:\n",
    "        print(\"List index out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3bc5604-fe2f-4da1-85f8-9198c6e01aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vallidate_annotation(completed_annotations, files_that_need_annotation, failed_to_annotate, annotation_not_complete, job_index):\n",
    "    for completed_annotation in completed_annotations:\n",
    "        #print(f\"{completed_annotation} ----\")\n",
    "        if (completed_annotation != 'attribute_groups_reference')  \\\n",
    "            and (completed_annotation != 'export_info') \\\n",
    "            and (completed_annotation != 'label_map') \\\n",
    "            and (completed_annotation != 'readme') \\\n",
    "            and (completed_annotation != 'label_colour_map'):\n",
    "            file = project_local.file.get_by_id(completed_annotation,with_instances=True)\n",
    "            url = file.__dict__['text']['tokens_url_signed']\n",
    "            data = extract_word_data(url)\n",
    "            word_count = 0\n",
    "            for word in data['nltk']['words']:\n",
    "                if (word['value'] == '\\n'):\n",
    "                    continue\n",
    "                word_count += 1\n",
    "            annotated_count = len(completed_annotations[completed_annotation]['instance_list'])      \n",
    "            if (word_count == annotated_count):\n",
    "                continue\n",
    "                #print(f\"SUCCESS: The file id is: {completed_annotation} and total annotation is {annotated_count} and word count is {word_count}\")\n",
    "            else:\n",
    "                job_value = {}\n",
    "                job_value['nickname'] = job_index['nickname']\n",
    "                job_value['index'] = job_index['index']\n",
    "                job_value['file'] = completed_annotation\n",
    "                jobs_with_data_index.append(job_value)\n",
    "                if (annotated_count) == 0:\n",
    "                    failed_to_annotate.append(job_value)\n",
    "                else:\n",
    "                    annotation_not_complete.append(job_value)\n",
    "                print(f\"ERROR: The file id is: {completed_annotation} and total annotation is {annotated_count} and word count is {word_count}\")\n",
    "                files_that_need_annotation.append(completed_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6488a03-f0a3-4481-8357-d0b41bb6b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_that_need_annotation = []\n",
    "failed_to_annotate = []\n",
    "annotation_not_complete = []\n",
    "for job_index in jobs_with_data_index[0:]:\n",
    "    print(f\"The job nickname is {job_index['nickname']} and the index is {job_index['index']}\")\n",
    "    results.refresh_from_dict(get_job[job_index['index']])\n",
    "    completed_annotations = results.generate_export()\n",
    "    vallidate_annotation(completed_annotations,files_that_need_annotation, failed_to_annotate, annotation_not_complete, job_index)\n",
    "print(len(files_that_need_annotation))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753508b-8472-4f99-80df-410846bb46fb",
   "metadata": {},
   "source": [
    "## Process incomplete annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebf38b-eb31-4cf7-9602-cf0b080bd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_not_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20993a25-a606-4248-a30b-421d9b46ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    # Handle double backticks first\n",
    "    s = s.replace('``', '\"')\n",
    "    # Handle other quote variations\n",
    "    s = s.replace('\"', '\"').replace('\"', '\"').replace('\\'\\'', '\"')\n",
    "    s = s.replace('\\\\', '')\n",
    "    s = s.replace('\\'s', 'is')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "719ee124-a0c6-4601-937c-46c3cde7fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def process_per_file_annotation(job_data):\n",
    "    try:\n",
    "        file_id = job_data['file']\n",
    "        file = project_local.file.get_by_id(file_id, with_instances=True)\n",
    "        data = extract_word_data(file.__dict__['text']['tokens_url_signed'])\n",
    "        \n",
    "        # Get current annotation count\n",
    "        num_annotated_text_index = len(file.__dict__['instance_list']) - 1\n",
    "        \n",
    "        # Count actual words (excluding newlines)\n",
    "        word_count = sum(1 for word in data['nltk']['words'] if word['value'] != '\\n')\n",
    "        \n",
    "        # Skip if only few words remaining\n",
    "        if abs(word_count - num_annotated_text_index) < 4:\n",
    "            print(f\"Skipping file {file_id}: only {abs(word_count - num_annotated_text_index)} words remaining\")\n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'job_index': job_data['index'],\n",
    "                'nickname': job_data['nickname'],\n",
    "                'file_id': job_data['file']\n",
    "            }\n",
    "\n",
    "        # Get remaining words for annotation\n",
    "        remaining_words = []\n",
    "        word_index = 0\n",
    "        actual_indices = []  # Track actual indices of remaining words\n",
    "        \n",
    "        for i, word in enumerate(data['nltk']['words']):\n",
    "            if word['value'] != '\\n':\n",
    "                if word_index >= num_annotated_text_index:\n",
    "                    remaining_words.append(word['value'])\n",
    "                    actual_indices.append(i)\n",
    "                word_index += 1\n",
    "\n",
    "        # Create prompt for remaining words\n",
    "        words = \"\\n\".join(remaining_words)\n",
    "        prompt = create_ner_prompt(words, schema_label_id_value)\n",
    "        print(prompt)\n",
    "        #return\n",
    "        response = get_response_with_tracking(prompt, job_data)\n",
    "        ai_annotation = json.loads(response)\n",
    "\n",
    "        # Process annotations\n",
    "        instance_list = file.__dict__['instance_list']\n",
    "        for i, (word_data, actual_idx) in enumerate(zip(ai_annotation, actual_indices)):\n",
    "            if normalize_string(data['nltk']['words'][actual_idx]['value']) == normalize_string(word_data['word']):\n",
    "                label_id = next((label['id'] for label in schema_label_id_value \n",
    "                               if label['name'] == word_data['tag']), None)\n",
    "                \n",
    "                if label_id:\n",
    "                    instance = {\n",
    "                        \"label_file_id\": label_id,\n",
    "                        \"start_token\": actual_idx,  # Use actual index from tokens\n",
    "                        \"end_token\": actual_idx,    # Use actual index from tokens\n",
    "                        \"type\": 'text_token'\n",
    "                    }\n",
    "                    instance_list.append(instance)\n",
    "\n",
    "        # Update and send annotations\n",
    "        file.__dict__['instance_list'] = instance_list\n",
    "        sent = send_preannotation_to_diffgram(file)\n",
    "        \n",
    "        return {\n",
    "            'status': 'success',\n",
    "            'job_index': job_data['index'],\n",
    "            'nickname': job_data['nickname'],\n",
    "            'file_id': job_data['file']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in job {job_data['nickname']}: {str(e)}\")\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'job_index': job_data['index'],\n",
    "            'nickname': job_data['nickname'],\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30b71e-8705-410c-b533-e7df521a5a0d",
   "metadata": {},
   "source": [
    "## Parallel process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5088abf1-6448-4013-9d75-e2555fba8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def process_failed_annotations(failed_files, max_workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all files for processing\n",
    "        futures = [\n",
    "            executor.submit(process_per_file_annotation, file)\n",
    "            for file in failed_files\n",
    "        ]\n",
    "        \n",
    "        # Track results\n",
    "        processed_files = []\n",
    "        for future in futures:\n",
    "            try:\n",
    "                result = future.result()\n",
    "                processed_files.append(result)\n",
    "                \n",
    "                # Assuming process_per_file_annotation returns a dict with status\n",
    "                if result.get('status') == 'success':\n",
    "                    print(f\"Successfully processed file {result.get('file_id')}\")\n",
    "                else:\n",
    "                    print(f\"Failed to process file {result.get('file_id')}: {result.get('error')}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Exception in worker thread: {str(e)}\")\n",
    "                \n",
    "        return processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8814da74-77c3-43b8-a5ee-bc9847a477f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_not_complete = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03231c98-5411-48e1-bc09-8d0f61a36423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_annotations(file_id, project_local):\n",
    "    url = f\"{DIFFGRAM_CONFIG['host']}/api/project/{DIFFGRAM_CONFIG['project_string_id']}/file/{file_id}/annotation/list\"\n",
    "    auth = project_local.session.auth\n",
    "    \n",
    "    data = {\"directory_id\":197,\n",
    "            \"job_id\":'null',\n",
    "            \"task_child_file_id\":20723}\n",
    "    \n",
    "    response = requests.post(\n",
    "        url, \n",
    "        json = data,\n",
    "        auth=auth\n",
    "    )\n",
    "    return resposnse.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6069e129-ff9c-4a0b-98f6-ca0bb7336fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_not_complete = [\n",
    " {'nickname': 'NER_train_batch_218', 'index': 31, 'file': '19747'},\n",
    " {'nickname': 'NER_train_batch_213', 'index': 36, 'file': '19573'},\n",
    " {'nickname': 'NER_train_batch_209', 'index': 40, 'file': '19465'},\n",
    " {'nickname': 'NER_train_batch_202', 'index': 47, 'file': '19234'},\n",
    " {'nickname': 'NER_train_batch_193', 'index': 56, 'file': '18936'},\n",
    " {'nickname': 'NER_train_batch_167', 'index': 82, 'file': '18110'},\n",
    " {'nickname': 'NER_train_batch_158', 'index': 91, 'file': '17842'},\n",
    " {'nickname': 'NER_train_batch_153', 'index': 96, 'file': '17653'},\n",
    " {'nickname': 'NER_train_batch_149', 'index': 100, 'file': '17554'},\n",
    " {'nickname': 'NER_train_batch_136', 'index': 113, 'file': '17113'},\n",
    " {'nickname': 'NER_train_batch_135', 'index': 114, 'file': '17084'},\n",
    " {'nickname': 'NER_train_batch_107', 'index': 142, 'file': '16203'},\n",
    " {'nickname': 'NER_train_batch_101', 'index': 148, 'file': '15999'},\n",
    " {'nickname': 'NER_train_batch_97', 'index': 152, 'file': '15889'},\n",
    " {'nickname': 'NER_train_batch_89', 'index': 160, 'file': '15628'},\n",
    " {'nickname': 'NER_train_batch_83', 'index': 166, 'file': '15434'},\n",
    " {'nickname': 'NER_train_batch_75', 'index': 174, 'file': '15162'},\n",
    " {'nickname': 'NER_train_batch_59', 'index': 190, 'file': '14658'},\n",
    " {'nickname': 'NER_train_batch_57', 'index': 192, 'file': '14588'},\n",
    " {'nickname': 'NER_train_batch_51', 'index': 198, 'file': '14410'},\n",
    " {'nickname': 'NER_train_batch_42', 'index': 207, 'file': '14111'},\n",
    " {'nickname': 'NER_train_batch_28', 'index': 221, 'file': '13669'},\n",
    " {'nickname': 'NER_train_batch_22', 'index': 227, 'file': '13480'},\n",
    " {'nickname': 'NER_train_batch_16', 'index': 233, 'file': '13298'},\n",
    " {'nickname': 'NER_train_batch_5', 'index': 244, 'file': '12875'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d237754e-778c-4728-97d8-50fb6e90637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Named Entity Recognition system for legislative text.\n",
      "Your task is to label each word using only the following allowed tags:\n",
      "- B-ACT_ID\n",
      "- B-ACT_NAME\n",
      "- B-AUTHORITY\n",
      "- B-CHUNK_ID\n",
      "- B-DEFINITION\n",
      "- B-METADATA_FIELD\n",
      "- B-METADATA_VALUE\n",
      "- B-REGULATION_ID\n",
      "- B-REQUIREMENT\n",
      "- B-SECTION_ID\n",
      "- B-SECTION_NAME\n",
      "- B-SECTION_REF\n",
      "- B-SEQUENCE_ID\n",
      "- B-SUBSECTION_REF\n",
      "- I-ACT_ID\n",
      "- I-ACT_NAME\n",
      "- I-AUTHORITY\n",
      "- I-CHUNK_ID\n",
      "- I-DEFINITION\n",
      "- I-METADATA_FIELD\n",
      "- I-METADATA_VALUE\n",
      "- I-REGULATION_ID\n",
      "- I-REQUIREMENT\n",
      "- I-SECTION_ID\n",
      "- I-SECTION_NAME\n",
      "- I-SECTION_REF\n",
      "- I-SEQUENCE_ID\n",
      "- I-SUBSECTION_REF\n",
      "- O\n",
      "\n",
      "Rules:\n",
      "1. Default to 'O' tag - most words should be tagged as Outside\n",
      "2. Only tag these specific elements:\n",
      "   - Section references (e.g., \"section 46\" -> B-SECTION_REF, I-SECTION_REF)\n",
      "   - Subsection references (e.g., \"(2)\", \"(a)\" -> B-SUBSECTION_REF)\n",
      "   - Essential metadata fields and their values\n",
      "3. Tag principles:\n",
      "   - All punctuation should be 'O'\n",
      "   - Use B- prefix only for start of key references\n",
      "   - Use I- prefix for continuing words of same reference\n",
      "   - When in doubt, use 'O' tag\n",
      "\n",
      "Each space should be annotated separately. For e.g. If you see child 's annotate it as child and 's as two different words as there is a sapce between them. All ' s must be treated as one word 's.\n",
      "If there are no spaces between words like Act-Motor or 2subsection or 1in or b or ill. . treat this as one word. If b. and c. are separatd by a space then b. is one word and c. is another word. If there is a space between say en . then en is one word and the . is another word which should have its own label.\n",
      "\n",
      "Output format:\n",
      "[\n",
      "    {\"word\": \"section\", \"tag\": \"B-SECTION_REF\"},\n",
      "    {\"word\": \"46\", \"tag\": \"I-SECTION_REF\"},\n",
      "    {\"word\": \",\", \"tag\": \"O\"},\n",
      "    {\"word\": \"subsection\", \"tag\": \"O\"},\n",
      "    {\"word\": \"(\", \"tag\": \"O\"},\n",
      "    {\"word\": \"2\", \"tag\": \"B-SUBSECTION_REF\"},\n",
      "    {\"word\": \"'s\", \"tag\": \"O\"},\n",
      "    {\"word\": \")\", \"tag\": \"O\"}\n",
      "]\n",
      "\n",
      "Text to label:\n",
      "section\n",
      "333.\n",
      "current\n",
      "information\n",
      "may\n",
      "be\n",
      "found\n",
      "on\n",
      "the\n",
      "workers'compensation\n",
      "board\n",
      "website\n",
      "at\n",
      "www\n",
      ".\n",
      "worksafebc\n",
      ".\n",
      "com\n",
      "/\n",
      "en\n",
      "/\n",
      "law\n",
      "-\n",
      "policy\n",
      "/\n",
      "claims\n",
      "-\n",
      "rehabilitation\n",
      "/\n",
      "claims\n",
      "-\n",
      "related\n",
      "-\n",
      "consumer\n",
      "-\n",
      "price\n",
      "-\n",
      "index\n",
      "or\n",
      "may\n",
      "be\n",
      "obtained\n",
      "by\n",
      "calling\n",
      "your\n",
      "worksafebc\n",
      "regional\n",
      "office\n",
      ".\n",
      "]\n",
      "\n",
      "Provide only the JSON output with no additional explanation.\n",
      "Annotation update successful!\n",
      "Successfully processed file 17653\n"
     ]
    }
   ],
   "source": [
    "#for jobs_data in annotation_not_complete[3:]:\n",
    "#    print(job_data)\n",
    "annotation_not_complete = [{'nickname': 'NER_train_batch_153', 'index': 96, 'file': '17653'}]\n",
    "results = process_failed_annotations(annotation_not_complete, max_workers=10)\n",
    "#process_per_file_annotation(annotation_not_complete[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6becc39-7a4a-4e6f-b8c5-4086c8418e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
