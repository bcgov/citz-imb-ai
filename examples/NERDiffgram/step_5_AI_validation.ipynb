{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f372d86c-8a28-4c05-955b-340b166b1078",
   "metadata": {},
   "source": [
    "# Annotation Validation\n",
    "\n",
    "The purpose of this notebook is to double check if all the annotation are proplery annotated, nothing is skipped and if so how to re-annotate the document again using a more specialzied prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb1ec9-1faa-463f-a678-f5daeb15e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers diffgram neo4j anthropic pandas tqdm\n",
    "!pip install llama_index\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851dfee-a5ac-4672-9e26-a90a713fe181",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix-otel\n",
    "!pip install openinference-instrumentation-bedrock opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d66e7d3-8bb5-404f-b7d8-1dd64df2f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from diffgram import Project\n",
    "from typing import List, Dict, Optional\n",
    "import anthropic\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import requests\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b825a5-330a-461e-94b3-34df68e3adcd",
   "metadata": {},
   "source": [
    "## Connect to Diffgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92262a8b-0606-42e3-9b0b-17369a4bca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffgram project configuration\n",
    "DIFFGRAM_CONFIG = {\n",
    "    \"host\": \"http://dispatcher:8085\",\n",
    "    \"project_string_id\": \"translucenttracker\",\n",
    "    \"client_id\": \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "    \"client_secret\": \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f024a73c-90af-42f7-b3c4-127fcd8d04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize connection to Diffgram project\n",
    "project = Project(host=DIFFGRAM_CONFIG[\"host\"],\n",
    "        project_string_id = \"translucenttracker\",\n",
    "        client_id = \"LIVE__u3v8q0m7tx1p851dp0ap\",\n",
    "        client_secret = \"1qgd8as7xfcbuem6mw9j1z0xvjfmmvlagbugqr8z1g1ntypugr2ul24cce5k\"\n",
    "      )\n",
    "project_local = project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e079e2-5c90-40c9-acfc-b7aac6a36ba2",
   "metadata": {},
   "source": [
    "## Fetch Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec4ae7c-21ed-4e93-91bd-c73d55beada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and manage NER schema in Diffgram\n",
    "# Retrieve and process existing schema labels\n",
    "NER_schema_name = 'ENTITY_TRAINING_SCHEMA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786290bb-1789-4ca5-a554-e0c60ba4aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_list(id):\n",
    "    auth = project.session.auth\n",
    "    url = f\"{DIFFGRAM_CONFIG['host']}/api/project/{DIFFGRAM_CONFIG['project_string_id']}/labels?schema_id={id}\"\n",
    "    # Step 4: Make the POST request using the SDK's session auth\n",
    "    response = requests.get(url, auth=auth)\n",
    "    # Step 5: Handle the response\n",
    "    if response.status_code == 200:\n",
    "        #print(\"Annotation update successful!\")\n",
    "        #pprint.pprint(response.json())  # View the updated data\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)  # Print error details for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12eef65-6262-4b3c-ab55-c5c47b801ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Schemas in Diffgram:\n",
      "[\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 8,\n",
      "    \"is_default\": true,\n",
      "    \"member_created_id\": 1,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"Default Schema\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-04 22:16:17\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 9,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"NER_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:08:24\",\n",
      "    \"time_updated\": null\n",
      "  },\n",
      "  {\n",
      "    \"archived\": false,\n",
      "    \"id\": 11,\n",
      "    \"is_default\": false,\n",
      "    \"member_created_id\": 10,\n",
      "    \"member_updated_id\": null,\n",
      "    \"name\": \"ENTITY_TRAINING_SCHEMA\",\n",
      "    \"project_id\": 4,\n",
      "    \"time_created\": \"2025-02-05 17:20:02\",\n",
      "    \"time_updated\": null\n",
      "  }\n",
      "]\n",
      "Schema 'ENTITY_TRAINING_SCHEMA' already exists with id: 11\n",
      "{'B-CHUNK_ID', 'B-REQUIREMENT', 'B-AUTHORITY', 'I-METADATA_VALUE', 'I-DEFINITION', 'I-SEQUENCE_ID', 'I-ACT_ID', 'B-SECTION_ID', 'B-METADATA_FIELD', 'B-SECTION_NAME', 'B-ACT_ID', 'I-SECTION_NAME', 'I-CHUNK_ID', 'I-REGULATION_ID', 'I-SECTION_ID', 'B-METADATA_VALUE', 'I-ACT_NAME', 'B-REGULATION_ID', 'I-SUBSECTION_REF', 'I-REQUIREMENT', 'O', 'B-DEFINITION', 'I-METADATA_FIELD', 'I-AUTHORITY', 'B-SEQUENCE_ID', 'I-SECTION_REF', 'B-SECTION_REF', 'B-ACT_NAME', 'B-SUBSECTION_REF'}\n"
     ]
    }
   ],
   "source": [
    "schema_id = None\n",
    "\n",
    "# List the existing schemas in your Diffgram project.\n",
    "schemas = project.schema.list()\n",
    "schema_list = schemas\n",
    "print(\"Existing Schemas in Diffgram:\")\n",
    "print(json.dumps(schemas, indent=2))\n",
    "\n",
    "# Check if a schema with the name NER_schema_name already exists.\n",
    "for schema in schemas:\n",
    "    if schema.get('name') == NER_schema_name:\n",
    "        schema_id = schema.get('id')\n",
    "        break\n",
    "\n",
    "# If the schema does not exist, create a new one.\n",
    "if schema_id is None:\n",
    "    print(f\"Schema '{NER_schema_name}' not found. Creating a new one...\")\n",
    "    json_response = project.new_schema(name=NER_schema_name)\n",
    "    schema_id = json_response.get(\"id\")\n",
    "    print(f\"Created new schema with id: {schema_id}\")\n",
    "else:\n",
    "    print(f\"Schema '{NER_schema_name}' already exists with id: {schema_id}\")\n",
    "\n",
    "schema_labels = get_schema_list(schema_id)\n",
    "\n",
    "# Retrieve existing labels for the schema to avoid duplicates.\n",
    "schema_label_id_value = []\n",
    "if schema_labels is not None:\n",
    "    labels = schema_labels['labels_out']\n",
    "    for label in labels:\n",
    "        value = {}\n",
    "        value['id'] = label['id']\n",
    "        value['name'] = label['label']['name']\n",
    "        schema_label_id_value.append(value)\n",
    "\n",
    "existing_label_names = set()\n",
    "try:\n",
    "    schema_label_id_value[0]['name']\n",
    "    for label in schema_label_id_value:\n",
    "            label_name = label.get(\"name\")\n",
    "            if label_name:\n",
    "                existing_label_names.add(label_name)\n",
    "    print(existing_label_names)      \n",
    "except:\n",
    "     print(\"There are no schema labels\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7555c6-8f35-493b-8359-9dcd31197a30",
   "metadata": {},
   "source": [
    "## NER Validation Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ffb65-abeb-47b8-b8a0-cd54c1732f71",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af043435-eed9-441c-b42c-e1f9de7599b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_data(url):\n",
    "    # Original URL with localhost\n",
    "    # Replace localhost with ngrok URL (example: \"https://example.ngrok.io\")\n",
    "    file_url = url.replace(\"http://localhost:8085\", DIFFGRAM_CONFIG['host'])\n",
    "\n",
    "    # Make the GET request to fetch the file\n",
    "    response = requests.get(file_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON content into a Python dictionary\n",
    "        data = response.json()  # Assuming the file is in JSON format\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34eb37da-e112-4888-bcc1-5728dce75f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for processing Diffgram annotations\n",
    "# Extract and format word-level data from files\n",
    "def get_file_number(completed_annotations, files_index_in_job):\n",
    "    data = []\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    data_index = 0\n",
    "    for completed_annotation in completed_annotations:\n",
    "        try:\n",
    "            file_index = int(completed_annotation)\n",
    "            files_index_in_job.append(completed_annotation)\n",
    "            #print(completed_annotation)\n",
    "            continue\n",
    "        except:\n",
    "            #print(f\"{completed_annotation} is not a file\")\n",
    "            continue\n",
    "            \n",
    "        #print(f\"{completed_annotation} ----\")\n",
    "        if (completed_annotation != 'attribute_groups_reference')  \\\n",
    "            and (completed_annotation != 'export_info') \\\n",
    "            and (completed_annotation != 'label_map') \\\n",
    "            and (completed_annotation != 'readme') \\\n",
    "            and (completed_annotation != 'label_colour_map'):\n",
    "            sentence_local = []\n",
    "            labels_local = []\n",
    "\n",
    "            # First get the point where the annotation is started\n",
    "            for start in completed_annotations[completed_annotation]['instance_list']:\n",
    "                if 'start_token' in start:\n",
    "                    start_token =  start['start_token']\n",
    "                    break\n",
    "\n",
    "            #start_token = completed_annotations[completed_annotation]['instance_list'][0]['start_token']\n",
    "            for annotated_index in range(start_token, len(completed_annotations[completed_annotation]['text']['tokens']['words'])):\n",
    "                # check if this text is annotated\n",
    "                for data in completed_annotations[completed_annotation]['instance_list']:\n",
    "                    if 'start_token' in data:\n",
    "                        if annotated_index == data['start_token']:\n",
    "                            sentence_local.append(completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value'])\n",
    "                            labels_local.append(completed_annotations['label_map'][str(data['label_file_id'])])\n",
    "                            #print(f\"{completed_annotations[completed_annotation]['text']['tokens']['words'][annotated_index]['value']} - {completed_annotations['label_map'][str(data['label_file_id'])]}\")\n",
    "                            break;\n",
    "            sentences.append(sentence_local)       \n",
    "            labels.append(labels_local)\n",
    "            data_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94494b-c88b-4c3a-aa59-bbd8e784a6c3",
   "metadata": {},
   "source": [
    "## Scan all the tasks\n",
    "in each task see if the data has annotation\n",
    "if not then add the task id to annotation pending bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2fc04b-db61-4887-a993-2f911bc6ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_pending = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e83d2f-db1b-4d90-a2f0-0849a1997caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = project_local.job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc2431e-4a5e-45da-ae27-1fb963743bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_job = project_local.job.list(limit=10000, page_number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987640d3-0c15-4f7e-ae25-fa2033f42600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "print(len(get_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03fa38f-bdf3-4a9e-bf12-72672ff5982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_data_index = []\n",
    "for job_key, job_list in enumerate(get_job):\n",
    "    try:\n",
    "        nickname = job_list['attached_directories_dict']['attached_directories_list'][0]['nickname']\n",
    "        if nickname:\n",
    "            job_value = {}\n",
    "            job_value['nickname'] = nickname\n",
    "            job_value['index'] = job_key\n",
    "            jobs_with_data_index.append(job_value)\n",
    "        #print(nickname)\n",
    "    except KeyError:\n",
    "        print(\"Key not found.\")\n",
    "    except IndexError:\n",
    "        print(\"List index out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97147f-4648-4e2a-9772-3bd5efc36c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_with_data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069f7ff8-8f8d-418b-a957-49443b1b264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vallidate_annotation(completed_annotations, files_that_need_annotation, failed_to_annotate, annotation_not_complete, job_index, incorrect_count):\n",
    "    for completed_annotation in completed_annotations:\n",
    "        #print(f\"{completed_annotation} ----\")\n",
    "        if (completed_annotation != 'attribute_groups_reference')  \\\n",
    "            and (completed_annotation != 'export_info') \\\n",
    "            and (completed_annotation != 'label_map') \\\n",
    "            and (completed_annotation != 'readme') \\\n",
    "            and (completed_annotation != 'label_colour_map'):\n",
    "            file = project_local.file.get_by_id(completed_annotation,with_instances=True)\n",
    "            url = file.__dict__['text']['tokens_url_signed']\n",
    "            data = extract_word_data(url)\n",
    "            word_count = 0\n",
    "            for word in data['nltk']['words']:\n",
    "                if (word['value'] == '\\n'):\n",
    "                    continue\n",
    "                word_count += 1\n",
    "            annotated_count = len(completed_annotations[completed_annotation]['instance_list'])    \n",
    "\n",
    "            ## Count the number of instances\n",
    "            num_annotated_text_index =  len(file.__dict__['instance_list'])\n",
    "\n",
    "            job_value = {}\n",
    "            job_value['nickname'] = job_index['nickname']\n",
    "            job_value['index'] = job_index['index']\n",
    "            job_value['file'] = completed_annotation\n",
    "                    \n",
    "            if (word_count == annotated_count):\n",
    "                continue\n",
    "                #print(f\"SUCCESS: The file id is: {completed_annotation} and total annotation is {annotated_count} and word count is {word_count}\")\n",
    "            elif(word_count - num_annotated_text_index < 4):\n",
    "                diff  = abs(word_count - num_annotated_text_index)\n",
    "                incorrect_count.append(job_value)\n",
    "                print(f\"skipping:  file id {completed_annotation} of task {job_index['nickname']} of index {job_index['index']} diff {diff}\") \n",
    "                continue\n",
    "            else:\n",
    "                #jobs_with_data_index.append(job_value)\n",
    "                if (annotated_count) == 0:\n",
    "                    failed_to_annotate.append(job_value)\n",
    "                else:\n",
    "                    annotation_not_complete.append(job_value)\n",
    "                print(f\"ERROR: The file id is: {completed_annotation} and total annotation is {annotated_count} and word count is {word_count}\")\n",
    "                files_that_need_annotation.append(completed_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1eb97e64-200a-4f00-b605-4cd5fcc804c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jobs_with_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c4a22-6f43-4110-bca2-53c1bcc10720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job nickname is NER_train_batch_249 and the index is 0\n",
      "The job nickname is NER_train_batch_248 and the index is 1\n",
      "skipping:  file id 20693 of task NER_train_batch_248 of index 1 diff 2\n",
      "skipping:  file id 20718 of task NER_train_batch_248 of index 1 diff 1\n",
      "The job nickname is NER_train_batch_247 and the index is 2\n",
      "The job nickname is NER_train_batch_246 and the index is 3\n"
     ]
    }
   ],
   "source": [
    "files_that_need_annotation = []\n",
    "failed_to_annotate = []\n",
    "annotation_not_complete = []\n",
    "incorrect_count = []\n",
    "for job_index in jobs_with_data_index:\n",
    "    print(f\"The job nickname is {job_index['nickname']} and the index is {job_index['index']}\")\n",
    "    results.refresh_from_dict(get_job[job_index['index']])\n",
    "    completed_annotations = results.generate_export()\n",
    "    vallidate_annotation(completed_annotations,files_that_need_annotation, failed_to_annotate, annotation_not_complete, job_index, incorrect_count)\n",
    "    #files_index_in_job = []\n",
    "    #get_file_number(completed_annotations, files_index_in_job, )\n",
    "    #print(files_index_in_job)\n",
    "    ## Extract the file data:\n",
    "print(len(files_that_need_annotation))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685434cd-2e01-4601-aeb0-b2bc90e7f6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
