{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PACKAGE INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers \n",
    "!pip install einops \n",
    "!pip install torchvision \n",
    "!pip install torch\n",
    "!pip install pillow \n",
    "!pip install accelerate \n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORTS AND CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define paths and configurations\n",
    "ROOT_FOLDER = 'images'\n",
    "OUTPUT_FILE = 'image_descriptions.json'\n",
    "SUPPORTED_FORMATS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')\n",
    "IGNORE_PATTERNS = ('.ipynb_checkpoints', '-checkpoint') # Add patterns to ignore\n",
    "\n",
    "# Create output file if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump({}, f)\n",
    "    print(f\"Created empty {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    \"\"\"Create a nested defaultdict for hierarchical storage.\"\"\"\n",
    "    return defaultdict(nested_dict)\n",
    "\n",
    "def convert_defaultdict_to_dict(d):\n",
    "    \"\"\"Convert defaultdict to regular dict for JSON serialization.\"\"\"\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: convert_defaultdict_to_dict(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image and return its description.\"\"\"\n",
    "    prompt = \"\"\"Provide a comprehensive and precise description of this image that could be used for future retrieval. Structure your response in the following format:\n",
    "\n",
    "    1. Image Type and Category:\n",
    "        - Identify the primary type (diagram, chart, seal, form, table, map, etc.)\n",
    "        - Note any specific subcategories or variations\n",
    "\n",
    "    2. Identifier Information:\n",
    "        - Document numbers, references, or codes visible\n",
    "        - Any dates or version information shown\n",
    "    - Page numbers or section markers\n",
    "\n",
    "    3. Content Description:\n",
    "        - Main subject matter or topic\n",
    "        - Key terms and specific language used\n",
    "        - Numbers, quantities, or measurements shown\n",
    "        - Any proper nouns or specific terminology\n",
    "\n",
    "    4. Visual Structure:\n",
    "        - Overall layout and organization\n",
    "        - Hierarchical relationships if present\n",
    "        - Connections between elements (arrows, lines, groupings)\n",
    "        - Color scheme and visual emphasis points\n",
    "\n",
    "    5. Distinctive Features:\n",
    "        - Unique or notable elements\n",
    "        - Special symbols or markings\n",
    "        - Unusual formatting or arrangements\n",
    "        - Key differentiating characteristics\n",
    "\n",
    "    Please write your description in clear, searchable language, including specific terms and identifiers that would be useful for finding this image later. Focus on accuracy and completeness rather than interpretation.\"\"\"\n",
    "\n",
    "    inputs = processor.process(\n",
    "        images=[Image.open(image_path)],\n",
    "        text=prompt\n",
    "    )\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.autocast(device_type=\"cpu\", enabled=True, dtype=torch.bfloat16):\n",
    "            output = model.generate_from_batch(\n",
    "                inputs,\n",
    "                GenerationConfig(max_new_tokens=2000, stop_strings=\"<|endoftext|>\"),\n",
    "                tokenizer=processor.tokenizer\n",
    "            )\n",
    "    \n",
    "    generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "    return processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MAIN PROCESSING LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize results dictionary\n",
    "    results = nested_dict()\n",
    "    \n",
    "    # Load existing descriptions if any\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "            # Convert existing results to nested defaultdict\n",
    "            for key, value in existing_results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    results[key].update(value)\n",
    "                else:\n",
    "                    results[key] = value\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Starting with empty results as {OUTPUT_FILE} is empty or invalid\")\n",
    "    \n",
    "    # Process directory structure\n",
    "    for dirpath, dirnames, filenames in os.walk(ROOT_FOLDER):\n",
    "        # Remove checkpoint directories from dirnames (modifies list in place)\n",
    "        dirnames[:] = [d for d in dirnames if not any(pattern in d for pattern in IGNORE_PATTERNS)]\n",
    "        \n",
    "        # Filter for image files, excluding checkpoints\n",
    "        image_files = [\n",
    "            f for f in filenames \n",
    "            if f.lower().endswith(SUPPORTED_FORMATS) \n",
    "            and not any(pattern in f for pattern in IGNORE_PATTERNS)\n",
    "        ]\n",
    "        \n",
    "        if image_files:\n",
    "            # Get relative path from root folder\n",
    "            rel_path = os.path.relpath(dirpath, ROOT_FOLDER)\n",
    "            \n",
    "            # Navigate to correct position in results dictionary\n",
    "            current_dict = results\n",
    "            if rel_path != '.':\n",
    "                for path_part in rel_path.split(os.sep):\n",
    "                    current_dict = current_dict[path_part]\n",
    "            \n",
    "            # Process each image\n",
    "            for filename in image_files:\n",
    "                image_path = os.path.join(dirpath, filename)\n",
    "                if filename not in current_dict:\n",
    "                    try:\n",
    "                        current_dict[filename] = process_image(image_path)\n",
    "                        print(f\"Processed: {image_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"Skipped (already processed): {image_path}\")\n",
    "                \n",
    "                # Save after each image (checkpoint)\n",
    "                with open(OUTPUT_FILE, 'w') as f:\n",
    "                    json.dump(convert_defaultdict_to_dict(results), f, indent=4)\n",
    "\n",
    "    print(f\"All images processed. Results saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
