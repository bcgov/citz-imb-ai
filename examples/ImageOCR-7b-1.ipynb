{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PACKAGE INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers \n",
    "!pip install einops \n",
    "!pip install torchvision \n",
    "!pip install torch\n",
    "!pip install pillow \n",
    "!pip install accelerate \n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORTS AND CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define paths and configurations\n",
    "ROOT_FOLDER = 'data/bclaws/images'\n",
    "OUTPUT_FILE = 'image_descriptions.json'\n",
    "SUPPORTED_FORMATS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')\n",
    "\n",
    "# Create output file if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump({}, f)\n",
    "    print(f\"Created empty {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    \"\"\"Create a nested defaultdict for hierarchical storage.\"\"\"\n",
    "    return defaultdict(nested_dict)\n",
    "\n",
    "def convert_defaultdict_to_dict(d):\n",
    "    \"\"\"Convert defaultdict to regular dict for JSON serialization.\"\"\"\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: convert_defaultdict_to_dict(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image and return its description.\"\"\"\n",
    "    prompt = \"\"\"Analyze and describe the image in detail. Address the following aspects:\n",
    "\n",
    "1. Main Subject: Identify the primary focus or theme of the image.\n",
    "2. Visual Details: Describe key colors, shapes, and significant visual elements.\n",
    "3. Text Content: Summarize any visible text, highlighting main topics and important points.\n",
    "4. Layout and Structure: Outline how elements are arranged and any notable patterns.\n",
    "5. Symbols and Legends: Explain symbols, legends, or keys present in the image.\n",
    "6. Purpose and Context: Infer the likely purpose, audience, or context of the image.\n",
    "\n",
    "Provide a comprehensive description covering all relevant details observed in the image.\"\"\"\n",
    "\n",
    "    inputs = processor.process(\n",
    "        images=[Image.open(image_path)],\n",
    "        text=prompt\n",
    "    )\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.autocast(device_type=\"cpu\", enabled=True, dtype=torch.bfloat16):\n",
    "          output = model.generate_from_batch(\n",
    "              inputs,\n",
    "              GenerationConfig(max_new_tokens=2000, stop_strings=\"<|endoftext|>\"),\n",
    "              tokenizer=processor.tokenizer\n",
    "          )\n",
    "    \n",
    "    generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "    return processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MAIN PROCESSING LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize results dictionary\n",
    "    results = nested_dict()\n",
    "    \n",
    "    # Load existing descriptions if any\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "            # Convert existing results to nested defaultdict\n",
    "            for key, value in existing_results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    results[key].update(value)\n",
    "                else:\n",
    "                    results[key] = value\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Starting with empty results as {OUTPUT_FILE} is empty or invalid\")\n",
    "    \n",
    "    # Process directory structure\n",
    "    for dirpath, dirnames, filenames in os.walk(ROOT_FOLDER):\n",
    "        # Filter for image files\n",
    "        image_files = [f for f in filenames if f.lower().endswith(SUPPORTED_FORMATS)]\n",
    "        \n",
    "        if image_files:\n",
    "            # Get relative path from root folder\n",
    "            rel_path = os.path.relpath(dirpath, ROOT_FOLDER)\n",
    "            \n",
    "            # Navigate to correct position in results dictionary\n",
    "            current_dict = results\n",
    "            if rel_path != '.':\n",
    "                for path_part in rel_path.split(os.sep):\n",
    "                    current_dict = current_dict[path_part]\n",
    "            \n",
    "            # Process each image\n",
    "            for filename in image_files:\n",
    "                image_path = os.path.join(dirpath, filename)\n",
    "                if filename not in current_dict:\n",
    "                    try:\n",
    "                        current_dict[filename] = process_image(image_path)\n",
    "                        print(f\"Processed: {image_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"Skipped (already processed): {image_path}\")\n",
    "                \n",
    "                # Save after each image (checkpoint)\n",
    "                with open(OUTPUT_FILE, 'w') as f:\n",
    "                    json.dump(convert_defaultdict_to_dict(results), f, indent=4)\n",
    "\n",
    "    print(f\"All images processed. Results saved to '{OUTPUT_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
