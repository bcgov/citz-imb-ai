{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PACKAGE INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers \n",
    "!pip install einops \n",
    "!pip install torchvision \n",
    "!pip install torch\n",
    "!pip install pillow \n",
    "!pip install accelerate \n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORTS AND CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define paths and configurations\n",
    "ROOT_FOLDER = 'images'\n",
    "OUTPUT_FILE = 'image_descriptions.json'\n",
    "SUPPORTED_FORMATS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg')\n",
    "IGNORE_PATTERNS = ('.ipynb_checkpoints', '-checkpoint') # Add patterns to ignore\n",
    "\n",
    "# Create output file if it doesn't exist\n",
    "if not os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        json.dump({}, f)\n",
    "    print(f\"Created empty {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODEL INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'allenai/Molmo-7B-D-0924',\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype='auto',\n",
    "    device_map='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    \"\"\"Create a nested defaultdict for hierarchical storage.\"\"\"\n",
    "    return defaultdict(nested_dict)\n",
    "\n",
    "def convert_defaultdict_to_dict(d):\n",
    "    \"\"\"Convert defaultdict to regular dict for JSON serialization.\"\"\"\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: convert_defaultdict_to_dict(v) for k, v in d.items()}\n",
    "    return d\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image and return its description.\"\"\"\n",
    "    prompt = \"\"\"Provide a comprehensive and precise description of this image that could be used for future retrieval. Structure your response in the following format:\n",
    "\n",
    "    1. Image Type and Category:\n",
    "        - Identify the primary type (diagram, chart, seal, form, table, map, etc.)\n",
    "        - Note any specific subcategories or variations\n",
    "\n",
    "    2. Identifier Information:\n",
    "        - Document numbers, references, or codes visible\n",
    "        - Any dates or version information shown\n",
    "    - Page numbers or section markers\n",
    "\n",
    "    3. Content Description:\n",
    "        - Main subject matter or topic\n",
    "        - Key terms and specific language used\n",
    "        - Numbers, quantities, or measurements shown\n",
    "        - Any proper nouns or specific terminology\n",
    "\n",
    "    4. Visual Structure:\n",
    "        - Overall layout and organization\n",
    "        - Hierarchical relationships if present\n",
    "        - Connections between elements (arrows, lines, groupings)\n",
    "        - Color scheme and visual emphasis points\n",
    "\n",
    "    5. Distinctive Features:\n",
    "        - Unique or notable elements\n",
    "        - Special symbols or markings\n",
    "        - Unusual formatting or arrangements\n",
    "        - Key differentiating characteristics\n",
    "\n",
    "    Please write your description in clear, searchable language, including specific terms and identifiers that would be useful for finding this image later. Focus on accuracy and completeness rather than interpretation.\"\"\"\n",
    "\n",
    "    inputs = processor.process(\n",
    "        images=[Image.open(image_path)],\n",
    "        text=prompt\n",
    "    )\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.autocast(device_type=\"cpu\", enabled=True, dtype=torch.bfloat16):\n",
    "            output = model.generate_from_batch(\n",
    "                inputs,\n",
    "                GenerationConfig(max_new_tokens=2000, stop_strings=\"<|endoftext|>\"),\n",
    "                tokenizer=processor.tokenizer\n",
    "            )\n",
    "    \n",
    "    generated_tokens = output[0,inputs['input_ids'].size(1):]\n",
    "    return processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MAIN PROCESSING LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize results dictionary\n",
    "    results = nested_dict()\n",
    "    \n",
    "    # Load existing descriptions if any\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "            # Convert existing results to nested defaultdict\n",
    "            for key, value in existing_results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    results[key].update(value)\n",
    "                else:\n",
    "                    results[key] = value\n",
    "        print(f\"Loaded existing results from {OUTPUT_FILE}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Starting with empty results as {OUTPUT_FILE} is empty or invalid\")\n",
    "\n",
    "    # Keep track of all possible image paths\n",
    "    all_image_paths = set()\n",
    "    processed_images = set()\n",
    "\n",
    "    # First pass: collect all image paths and already processed images\n",
    "    for dirpath, dirnames, filenames in os.walk(ROOT_FOLDER):\n",
    "        # Remove checkpoint directories\n",
    "        dirnames[:] = [d for d in dirnames if not any(pattern in d for pattern in IGNORE_PATTERNS)]\n",
    "        \n",
    "        # Filter for valid image files\n",
    "        image_files = [\n",
    "            f for f in filenames \n",
    "            if f.lower().endswith(SUPPORTED_FORMATS) \n",
    "            and not any(pattern in f for pattern in IGNORE_PATTERNS)\n",
    "        ]\n",
    "\n",
    "        for filename in image_files:\n",
    "            # Get relative path from root folder\n",
    "            rel_path = os.path.relpath(dirpath, ROOT_FOLDER)\n",
    "            \n",
    "            # Store full path for processing\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            all_image_paths.add(full_path)\n",
    "\n",
    "            # Check if image is already in results\n",
    "            current_dict = results\n",
    "            if rel_path != '.':\n",
    "                try:\n",
    "                    for path_part in rel_path.split(os.sep):\n",
    "                        current_dict = current_dict[path_part]\n",
    "                    if filename in current_dict:\n",
    "                        processed_images.add(full_path)\n",
    "                except (KeyError, TypeError):\n",
    "                    continue\n",
    "\n",
    "    # Calculate images that need processing\n",
    "    images_to_process = all_image_paths - processed_images\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"Total images found: {len(all_image_paths)}\")\n",
    "    print(f\"Already processed: {len(processed_images)}\")\n",
    "    print(f\"Remaining to process: {len(images_to_process)}\")\n",
    "    \n",
    "    # If no new images to process, exit\n",
    "    if not images_to_process:\n",
    "        print(\"\\nNo new images to process. Exiting...\")\n",
    "        return\n",
    "\n",
    "    # Ask for confirmation before proceeding\n",
    "    proceed = input(f\"\\nProceed with processing {len(images_to_process)} images? (y/n): \")\n",
    "    if proceed.lower() != 'y':\n",
    "        print(\"Processing cancelled by user.\")\n",
    "        return\n",
    "\n",
    "    # Second pass: process only new images\n",
    "    count = 0\n",
    "    total = len(images_to_process)\n",
    "    \n",
    "    for image_path in sorted(images_to_process):  # Sort for consistent ordering\n",
    "        count += 1\n",
    "        rel_path = os.path.relpath(os.path.dirname(image_path), ROOT_FOLDER)\n",
    "        filename = os.path.basename(image_path)\n",
    "        \n",
    "        print(f\"\\nProcessing image {count}/{total}: {image_path}\")\n",
    "        \n",
    "        # Navigate to correct position in results dictionary\n",
    "        current_dict = results\n",
    "        if rel_path != '.':\n",
    "            for path_part in rel_path.split(os.sep):\n",
    "                current_dict = current_dict[path_part]\n",
    "        \n",
    "        try:\n",
    "            current_dict[filename] = process_image(image_path)\n",
    "            print(f\"✓ Successfully processed: {image_path}\")\n",
    "            \n",
    "            # Save after each successful processing\n",
    "            with open(OUTPUT_FILE, 'w') as f:\n",
    "                json.dump(convert_defaultdict_to_dict(results), f, indent=4)\n",
    "            print(f\"✓ Progress saved to {OUTPUT_FILE}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✕ Error processing {image_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total images processed in this run: {count}\")\n",
    "    print(f\"Results saved to: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
