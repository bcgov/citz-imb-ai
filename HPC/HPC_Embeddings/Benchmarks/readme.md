
| **Benchmark Category** | **Benchmark** | **Purpose** | **Measurement** | **Actual Benchmark** | **How the Test Was Done** | **Notes** |
|------------------------|---------------|-------------|-----------------|----------------------|---------------------------|-----------|
| Data Handling | Data Transfer from HDD to DRAM | Measure data loading speed | Time to transfer a fixed size of data (e.g., 10GB) | | Transferred 10GB from HDD to DRAM using `dd` command | Ensure consistent data size and disk conditions |
| Data Handling | Parsing XML Files | Measure parsing speed | Time to parse a set number of XML files (e.g., 1000 files) | | Used a custom C parser to process 1000 XML files | Use a consistent XML structure for testing |
| Data Handling | Splitting Acts into Sections | Measure efficiency of document splitting | Time to split a large document into sections (e.g., 1000 acts) | | Implemented a section splitter in C, measured time taken | Verify accuracy of splits |
| Data Handling | Tokenizing Text into 256 Token Chunks | Measure tokenization speed | Time to tokenize a large text corpus into 256-token chunks | | Used a tokenization library to split text into 256-token chunks | Ensure uniform text distribution |
| Data Handling | Creating Embeddings | Measure embedding generation speed | Time to generate embeddings for tokenized chunks (e.g., 10,000 chunks) | | Used ONNX Runtime to generate embeddings for tokenized chunks | Record hardware specifications during the test |
| Hardware Utilization | Using AVX-512 Instructions | Demonstrate impact of AVX-512 instructions | Compare time taken for vectorized operations with/without AVX-512 | | Ran vectorized operations with and without AVX-512 instructions | Document CPU capabilities |
| Hardware Utilization | NUMA Node Optimization | Measure performance with NUMA-aware optimization | Compare latency and throughput of memory-intensive tasks with/without NUMA optimization | | Ran memory-intensive tasks with and without NUMA optimizations | Test on multi-socket systems |
| Hardware Utilization | MPI for Distributed Processing | Demonstrate efficiency of distributed processing | Time to complete a parallelized task across multiple nodes using MPI | | Ran a parallelized matrix multiplication task using MPI | Record inter-node communication details |
| Hardware Utilization | Multi-Threading with OpenMP | Measure efficiency of multi-threading | Compare performance of a multi-threaded application with varying numbers of threads | | Implemented multi-threaded sorting using OpenMP, varied thread counts | Adjust thread counts systematically |
| Hardware Utilization | Cache Optimization | Measure impact of cache optimization | Time taken to perform repeated access to datasets of varying sizes | | Ran repeated access benchmarks with datasets sized for L1, L2, and L3 caches | Monitor cache hit/miss rates |
| System Performance | End-to-End Pipeline Execution | Measure overall pipeline performance | Time to execute the entire data processing pipeline on a fixed dataset | | Ran full pipeline from HDD to embedding generation | Ensure pipeline consistency |
| System Performance | Throughput and Latency under Load | Measure system behavior under load | Throughput (tasks/sec) and latency (time/task) with increasing load | | Incrementally increased task load and measured throughput and latency | Monitor system stability |
| System Performance | Energy Consumption and Efficiency | Measure power usage | Energy consumption during various tasks under different hardware configurations | | Used a power meter to measure energy consumption during benchmarks | Record energy metrics systematically |
| System Performance | Fault Tolerance and Recovery Time | Measure system recovery time | Time taken for the system to recover from simulated hardware failures or crashes | | Simulated hardware failures, measured recovery times | Document recovery procedures |
| Additional Considerations | Scalability Tests | Measure system scalability | Performance metrics as data size and number of nodes increase | | Increased data size and node count, measured performance metrics | Evaluate scalability limits |
| Additional Considerations | Comparison with Alternative Architectures | Provide comparative benchmarks | Performance comparison against alternative hardware configurations | | Ran benchmarks on alternative hardware configurations | Ensure hardware variability |
